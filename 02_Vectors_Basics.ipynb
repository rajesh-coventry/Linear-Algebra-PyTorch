{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3215f3f",
   "metadata": {},
   "source": [
    "# **Basics: Vectors:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb22589",
   "metadata": {},
   "source": [
    "From a mathematical perspective, vectors are ordered collections of numbers that represent quantities with both magnitude and direction. In linear algebra, a vector can be visualized as an arrow in space, where the length represents magnitude and the orientation represents direction. Mathematically, vectors are elements of vector spaces and can be added together, scaled by constants, and used in operations like `dot products` and `cross products`. They serve as fundamental building blocks for describing geometric transformations, solving systems of linear equations, and representing multidimensional data.\n",
    "\n",
    "In deep learning, vectors take on a more abstract role as numerical representations of data features or learned patterns. Input data like images, text, or audio gets converted into high-dimensional vectors called `embeddings` that capture semantic meaning and relationships. These vectors flow through neural networks, where each layer transforms them through matrix operations to extract increasingly complex features. The network learns to map input vectors to output vectors that solve specific tasks, with the vector representations becoming more meaningful and useful as the model trains on data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41589cbc",
   "metadata": {},
   "source": [
    "Vectors have several important characteristics. \n",
    "\n",
    "1. **`Dimensionality`**: The number of numbers in the vector\n",
    "\n",
    "2. **`Orientation`**: Whether the vector is in column orientation (standing up tall) or row\n",
    "orientation (laying flat and wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b55b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "asList = [1,2,3] # vector as a list \n",
    "asArray = np.array([1,2,3])#  Vector as 1D array\n",
    "rowVec = np.array([ [1,2,3] ]) # Vector as a row\n",
    "colVec = np.array([ [1],[2],[3] ]) # vector as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8a94be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asList: (3,)\n",
      "asArray: (3,)\n",
      "rowVec: (1, 3)\n",
      "colVec: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'asList: {np.shape(asList)}')\n",
    "print(f'asArray: {asArray.shape}')\n",
    "print(f'rowVec: {rowVec.shape}')\n",
    "print(f'colVec: {colVec.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f0b1b",
   "metadata": {},
   "source": [
    "The 1D array `asArray` is of size `(3,)`, whereas the\n",
    "orientation-endowed vectors are `2D arrays` and are stored as size `(1,3)` or\n",
    "`(3,1)` depending on the orientation. Dimensions are always listed as\n",
    "`(rows,columns)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91d938",
   "metadata": {},
   "source": [
    "### **Geometry of Vectors:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4acb06",
   "metadata": {},
   "source": [
    "Ordered list of numbers is the algebraic interpretation of a vector; the\n",
    "geometric interpretation of a vector is a straight line with a specific length\n",
    "(also called magnitude) and direction (also called angle; it is computed\n",
    "relative to the positive x-axis). The two points of a vector are called the tail\n",
    "(where it starts) and the head (where it ends); the head often has an arrow\n",
    "tip to disambiguate from the tail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff32bb6",
   "metadata": {},
   "source": [
    "Geometrically, a vector represents a directed line segment in space - essentially an arrow that has both a starting point and an endpoint. The length of this arrow corresponds to the vector's magnitude (how much of the quantity it represents), while the direction the arrow points indicates the vector's direction. For example, a velocity vector shows both how fast an object is moving (magnitude) and which way it's going (direction).\n",
    "\n",
    "In coordinate systems, vectors are often drawn starting from the origin and extending to a point whose coordinates match the vector's components. A 2D vector [3, 4] would be drawn as an arrow from (0,0) to (3,4), with a length of 5 units and pointing northeast. This geometric representation makes vector operations intuitive: adding vectors corresponds to placing them head-to-tail to see the resultant displacement, scaling a vector stretches or shrinks the arrow, and the dot product relates to the angle between two vectors. This visual interpretation helps explain why vectors are so powerful for describing physical phenomena like forces, velocities, and electromagnetic fields in space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e05125",
   "metadata": {},
   "source": [
    "### **Algebric View of Vectors:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cc4f9",
   "metadata": {},
   "source": [
    "Algebraically, vectors are elements of vector spaces that satisfy specific axioms and can be manipulated using formal rules and operations. A vector space is defined by eight fundamental properties: closure under addition and scalar multiplication, associativity and commutativity of addition, existence of additive identity (zero vector) and additive inverse, distributivity of scalar multiplication over vector addition and field addition, and scalar multiplication by the multiplicative identity equals the original vector. This algebraic structure allows vectors to be treated as abstract mathematical objects that can be added, subtracted, and scaled according to these well-defined rules.\n",
    "\n",
    "In this algebraic view, vectors are represented as n-tuples of numbers from a field (usually real or complex numbers), where operations are performed component-wise. For instance, vector addition becomes element-wise addition of corresponding components, and scalar multiplication scales each component by the same factor. This algebraic framework enables powerful techniques like linear transformations (represented as matrices), eigenvalue decomposition, and basis changes. The algebraic interpretation also extends to abstract vector spaces where \"vectors\" might not have geometric meaning at all - like function spaces where polynomials or continuous functions are treated as vectors and manipulated using the same algebraic rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3ec609",
   "metadata": {},
   "source": [
    "### **Vectors in Deep Learning:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e45aa",
   "metadata": {},
   "source": [
    "From a data science perspective, vectors are fundamental data structures that represent observations, features, or samples in numerical form. Each vector typically represents a single data point where each component corresponds to a specific feature or variable - for example, a customer might be represented as a vector `[age, income, spending_score]`. Data scientists use vectors to encode categorical variables through techniques like one-hot encoding, perform dimensionality reduction with methods like `PCA`, and calculate similarities between data points using distance metrics. Vector operations enable core data science tasks like clustering (grouping similar vectors), classification (finding decision boundaries in vector space), and regression (fitting functions to vector data).\n",
    "\n",
    "In deep learning, vectors take on a more dynamic role as both input representations and learned feature encodings. Raw data gets transformed into dense vector representations called `embeddings` that capture semantic relationships - words, images, or users become points in high-dimensional space where similar items cluster together. Neural networks process these vectors through layers of matrix multiplications and non-linear activations, progressively transforming input vectors into increasingly abstract feature representations. The network learns to map input vectors to output vectors that solve specific tasks, with techniques like `attention mechanisms` allowing models to dynamically weight different parts of vector representations. Modern deep learning relies heavily on vector databases and similarity search to enable applications like `recommendation systems`, `semantic search`, and `retrieval-augmented generation`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea8288",
   "metadata": {},
   "source": [
    "**Here are the main vector operations:**\n",
    "\n",
    "1. **Basic Operations:**\n",
    "    - Addition\n",
    "    - Subtraction\n",
    "    - Scalar multiplication\n",
    "    - Scalar division\n",
    "\n",
    "2. **Products:**\n",
    "    - Dot product (scalar product)\n",
    "    - Cross product (vector product)\n",
    "    - Outer product\n",
    "    - Triple product (scalar triple product and vector triple product)\n",
    "\n",
    "3. **Magnitude and Direction:**\n",
    "    - Magnitude (norm)\n",
    "    - Unit vector (normalization)\n",
    "    - Distance between vectors\n",
    "\n",
    "4. **Advanced Operations:**\n",
    "    - Projection (vector projection and scalar projection)\n",
    "    - Angle between vectors\n",
    "    - Linear combination\n",
    "    - Hadamard product (element-wise multiplication)\n",
    "\n",
    "5. **Matrix-Related:**\n",
    "    - Matrix-vector multiplication\n",
    "    - Vector-matrix multiplication\n",
    "    - Transpose\n",
    "\n",
    "5. **Geometric Operations:**\n",
    "    - Reflection\n",
    "    - Rotation\n",
    "    - Translation (though vectors themselves don't translate, points do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73332b3b",
   "metadata": {},
   "source": [
    "### **Vectors in PyTorch:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c36a220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From list: tensor([1, 2, 3, 4, 5])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. From Python lists\n",
    "vec1 = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(\"From list:\", vec1)\n",
    "print(vec1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "184c87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero vector: tensor([0., 0., 0., 0., 0.])\n",
      "Ones vector: tensor([1., 1., 1., 1., 1.])\n",
      "Range vector: tensor([0, 2, 4, 6, 8])\n",
      "Linspace vector: tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
      "Random normal: tensor([ 0.2581, -0.7623, -1.6361,  1.4994,  0.7301])\n",
      "Random uniform: tensor([0.8279, 0.2073, 0.6335, 0.9465, 0.2487])\n",
      "Random integers: tensor([6, 7, 4, 5, 8])\n",
      "From NumPy: tensor([1, 2, 3, 4, 5])\n",
      "Float32 vector: tensor([1., 2., 3.])\n",
      "Int64 vector: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 2. Using specific creation functions\n",
    "vec2 = torch.zeros(5)          # Zero vector\n",
    "vec3 = torch.ones(5)           # Ones vector\n",
    "vec4 = torch.arange(0, 10, 2)  # Range vector\n",
    "vec5 = torch.linspace(0, 1, 5) # Linear space\n",
    "print(\"Zero vector:\", vec2)\n",
    "print(\"Ones vector:\", vec3)\n",
    "print(\"Range vector:\", vec4)\n",
    "print(\"Linspace vector:\", vec5)\n",
    "\n",
    "# 3. Random vectors\n",
    "vec6 = torch.randn(5)          # Normal distribution\n",
    "vec7 = torch.rand(5)           # Uniform [0,1]\n",
    "vec8 = torch.randint(0, 10, (5,))  # Random integers\n",
    "print(\"Random normal:\", vec6)\n",
    "print(\"Random uniform:\", vec7)\n",
    "print(\"Random integers:\", vec8)\n",
    "\n",
    "# 4. From NumPy arrays\n",
    "np_array = np.array([1, 2, 3, 4, 5])\n",
    "vec9 = torch.from_numpy(np_array)\n",
    "print(\"From NumPy:\", vec9)\n",
    "\n",
    "# 5. With specific data types\n",
    "vec10 = torch.tensor([1.0, 2.0, 3.0], dtype=torch.float32)\n",
    "vec11 = torch.tensor([1, 2, 3], dtype=torch.int64)\n",
    "print(\"Float32 vector:\", vec10)\n",
    "print(\"Int64 vector:\", vec11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379b31f",
   "metadata": {},
   "source": [
    "**VECTOR SHAPES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a06e9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D Vector:\n",
      "Vector: tensor([1, 2, 3, 4])\n",
      "Shape: torch.Size([4])\n",
      "Size: torch.Size([4])\n",
      "Number of dimensions: 1\n"
     ]
    }
   ],
   "source": [
    "# VECTOR SHAPES: \n",
    "\n",
    "# 1D vectors (default)\n",
    "vec_1d = torch.tensor([1, 2, 3, 4])\n",
    "print(\"\\n1D Vector:\")\n",
    "print(\"Vector:\", vec_1d)\n",
    "print(\"Shape:\", vec_1d.shape)\n",
    "print(\"Size:\", vec_1d.size())\n",
    "print(\"Number of dimensions:\", vec_1d.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ebe1b",
   "metadata": {},
   "source": [
    "**1D vector is also called 1D array.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a948639b",
   "metadata": {},
   "source": [
    "**A 1D array with 4 elements has `one dimension`, regardless of how many elements it contains. The four elements indicate the `size of the array`, not the number of dimensions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d20d5cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_1d.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73999360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_1d.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49221f83",
   "metadata": {},
   "source": [
    "**ROW VS COLUMN VECTORS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e79cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row Vector (1 x n):\n",
      "Vector: tensor([[1, 2, 3, 4]])\n",
      "Shape: torch.Size([1, 4])\n",
      "Number of Dimensions: 2\n"
     ]
    }
   ],
   "source": [
    "# ROW VS COLUMN VECTORS:\n",
    "\n",
    "# Row vector (1 x n)\n",
    "row_vector = torch.tensor([[1, 2, 3, 4]])  # Note the double brackets\n",
    "print(\"\\nRow Vector (1 x n):\")\n",
    "print(\"Vector:\", row_vector)\n",
    "print(\"Shape:\", row_vector.shape)\n",
    "\n",
    "print(f\"Number of Dimensions: {row_vector.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c909b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_vector.shape # shape of the vectoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c2ffb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ff5b4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Vector (n x 1):\n",
      "Vector:\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "Shape: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Column vector (n x 1)\n",
    "col_vector = torch.tensor([[1], [2], [3], [4]])  # Each element in its own list\n",
    "print(\"Column Vector (n x 1):\")\n",
    "print(\"Vector:\\n\", col_vector)\n",
    "print(\"Shape:\", col_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb5dba78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96c4f3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f50e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Vector: tensor([1, 2, 3, 4])\n",
      "\n",
      "1D to Row Vector:\n",
      "Original shape: torch.Size([4])\n",
      "Row vector shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Converting between representations\n",
    "vec_1d = torch.tensor([1, 2, 3, 4])\n",
    "print(f\"1D Vector: {vec_1d}\")\n",
    "\n",
    "# 1D to row vector\n",
    "row_from_1d = vec_1d.unsqueeze(0)  # Add dimension at position 0\n",
    "print(\"\\n1D to Row Vector:\")\n",
    "print(\"Original shape:\", vec_1d.shape)\n",
    "print(\"Row vector shape:\", row_from_1d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bd49b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D to Column Vector:\n",
      "Original 1D Vector:\n",
      " tensor([1, 2, 3, 4])\n",
      "Original shape: torch.Size([4])\n",
      "\n",
      "Column Vector:\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "Column vector shape: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# 1D to column vector \n",
    "\n",
    "col_from_1d = vec_1d.unsqueeze(1)  # Add dimension at position 1\n",
    "print(\"1D to Column Vector:\")\n",
    "print(f\"Original 1D Vector:\\n {vec_1d}\")\n",
    "print(\"Original shape:\", vec_1d.shape)\n",
    "print()\n",
    "print(f\"Column Vector:\\n {col_from_1d}\")\n",
    "print(\"Column vector shape:\", col_from_1d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cd785",
   "metadata": {},
   "source": [
    "- **A vector of shape \\( n \\) is indeed a 1D array.**\n",
    "- **A vector of shape \\( (n, 1) \\) represents an array with 1 column and \\( n \\) rows.**\n",
    "- **A vector of shape \\( (1, n) \\) represents an array with 1 row and \\( n \\) columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0efee143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Alternative reshaping:\n",
      "Row vector (view): torch.Size([1, 4])\n",
      "Column vector (view): torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Alternative ways to create row/column vectors\n",
    "\n",
    "row_alt = vec_1d.view(1, -1)  # Reshape to 1 x n\n",
    "col_alt = vec_1d.view(-1, 1)  # Reshape to n x 1\n",
    "print(\"\\nAlternative reshaping:\")\n",
    "print(\"Row vector (view):\", row_alt.shape)\n",
    "print(\"Column vector (view):\", col_alt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52776b",
   "metadata": {},
   "source": [
    "A vector can exist in multiple dimensions:\n",
    "\n",
    "   - **`1D vector`**: Represents a single line of elements.\n",
    "\n",
    "   - **`2D vector`**: Often seen as a matrix with rows and columns.\n",
    "\n",
    "   - **`Higher-dimensional vectors`**: Can exist in three dimensions (3D) or more, often used in advanced mathematical and computational contexts. \n",
    "\n",
    "Each additional dimension adds complexity and depth to the representation of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa668d0",
   "metadata": {},
   "source": [
    "**A vector of shape \\( (m, n) \\) is indeed referred to as a matrix or a 2D array.**   \n",
    "\n",
    "In general:\n",
    "   - If a data structure has a shape of \\( (m, n) \\), it is more accurate to describe it as a matrix or a 2D array rather than a vector.\n",
    "   \n",
    "   - The term \"tensor\" can also apply, especially in contexts involving higher dimensions (3D and beyond), but for \\( (m, n) \\), \"matrix\" or \"2D array\" is most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8761743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRACTICAL DIFFERENCES of Row and Column Vectors:\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PRACTICAL DIFFERENCES AND USE CASES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Matrix multiplication behavior\n",
    "A = torch.tensor([[1, 2], [3, 4]])  # 2x2 matrix\n",
    "v = torch.tensor([1, 2])            # 1D vector\n",
    "row_v = torch.tensor([[1, 2]])      # 1x2 row vector\n",
    "col_v = torch.tensor([[1], [2]])    # 2x1 column vector\n",
    "\n",
    "print(\"\\nMatrix A:\")\n",
    "print(A)\n",
    "print(\"Shape:\", A.shape)\n",
    "\n",
    "print(\"\\n1D Vector v:\")\n",
    "print(v)\n",
    "print(\"Shape:\", v.shape)\n",
    "\n",
    "# Matrix-vector multiplication with 1D vector\n",
    "result_1d = A @ v  # PyTorch treats 1D as column vector in this context\n",
    "print(\"\\nA @ v (1D vector):\")\n",
    "print(\"Result:\", result_1d)\n",
    "print(\"Shape:\", result_1d.shape)\n",
    "\n",
    "# Matrix-row vector multiplication\n",
    "try:\n",
    "    result_row = A @ row_v.T  # Need transpose for proper dimensions\n",
    "    print(\"\\nA @ row_v.T:\")\n",
    "    print(\"Result:\", result_row)\n",
    "    print(\"Shape:\", result_row.shape)\n",
    "except RuntimeError as e:\n",
    "    print(\"Error:\", e)\n",
    "\n",
    "# Matrix-column vector multiplication\n",
    "result_col = A @ col_v\n",
    "print(\"\\nA @ col_v:\")\n",
    "print(\"Result:\", result_col)\n",
    "print(\"Shape:\", result_col.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb25440",
   "metadata": {},
   "source": [
    "- **Tensor:** A data structure can be classified as a tensor regardless of its shape, including `scalars (0D)`, `vectors (1D)`, `matrices (2D)`, and `higher-dimensional arrays`.\n",
    "\n",
    "- **3D Tensor:** Often referred to as a `3D array`.\n",
    "\n",
    "- **2D Tensor:** Typically called a `matrix` or a `DataFrame` in libraries like pandas.\n",
    "\n",
    "- **2D Array:** Sometimes referred to as a `vector with two dimensions`, although this usage is less common.\n",
    "\n",
    "- **1D Tensor:** Often called a `1D matrix` and is considered a `true vector`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ec7ce",
   "metadata": {},
   "source": [
    "**BROADCASTING BEHAVIOR:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2a4d1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "BROADCASTING BEHAVIOR\n",
      "==============================\n",
      "\n",
      "Original vectors:\n",
      "1D vector: tensor([1, 2, 3]) Shape: torch.Size([3])\n",
      "Row vector: tensor([[1, 2, 3]]) Shape: torch.Size([1, 3])\n",
      "Column vector: tensor([[1],\n",
      "        [2],\n",
      "        [3]]) Shape: torch.Size([3, 1])\n",
      "\n",
      "Addition with broadcasting:\n",
      "1D + 1D: tensor([2, 4, 6]) Shape: torch.Size([3])\n",
      "Row + Column creates matrix:\n",
      "tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [4, 5, 6]])\n",
      "Shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# BROADCASTING BEHAVIOR:\n",
    "\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"BROADCASTING BEHAVIOR\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "# Broadcasting with different shapes\n",
    "vec_1d = torch.tensor([1, 2, 3])\n",
    "row_vec = torch.tensor([[1, 2, 3]])\n",
    "col_vec = torch.tensor([[1], [2], [3]])\n",
    "\n",
    "print(\"\\nOriginal vectors:\")\n",
    "print(\"1D vector:\", vec_1d, \"Shape:\", vec_1d.shape)\n",
    "print(\"Row vector:\", row_vec, \"Shape:\", row_vec.shape)\n",
    "print(\"Column vector:\", col_vec, \"Shape:\", col_vec.shape)\n",
    "\n",
    "# Addition with broadcasting\n",
    "print(\"\\nAddition with broadcasting:\")\n",
    "result1 = vec_1d + vec_1d  # Element-wise addition\n",
    "print(\"1D + 1D:\", result1, \"Shape:\", result1.shape)\n",
    "\n",
    "result2 = row_vec + col_vec  # Creates a 3x3 matrix!\n",
    "print(\"Row + Column creates matrix:\")\n",
    "print(result2)\n",
    "print(\"Shape:\", result2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8272e0",
   "metadata": {},
   "source": [
    "**WHEN TO USE ROW VS COLUMN VECTORS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15e51ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "WHEN TO USE ROW VS COLUMN VECTORS\n",
      "========================================\n",
      "\n",
      "Row vectors (1 x n) are useful for:\n",
      "- Representing single data samples/observations\n",
      "- Input to neural networks (batch of 1)\n",
      "- When you want to stack multiple vectors vertically\n",
      "\n",
      "Column vectors (n x 1) are useful for:\n",
      "- Traditional linear algebra operations\n",
      "- Representing features/weights in some contexts\n",
      "- When following mathematical conventions\n",
      "\n",
      "1D vectors are useful for:\n",
      "- Most PyTorch operations (default behavior)\n",
      "- Element-wise operations\n",
      "- When you don't need explicit matrix operations\n",
      "\n",
      "Stacked as rows (batch):\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Shape: torch.Size([3, 3])\n",
      "\n",
      "Stacked as columns (features):\n",
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n",
      "Shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# WHEN TO USE ROW VS COLUMN VECTORS\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"WHEN TO USE ROW VS COLUMN VECTORS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "print(\"\\nRow vectors (1 x n) are useful for:\")\n",
    "print(\"- Representing single data samples/observations\")\n",
    "print(\"- Input to neural networks (batch of 1)\")\n",
    "print(\"- When you want to stack multiple vectors vertically\")\n",
    "\n",
    "print(\"\\nColumn vectors (n x 1) are useful for:\")\n",
    "print(\"- Traditional linear algebra operations\")\n",
    "print(\"- Representing features/weights in some contexts\")\n",
    "print(\"- When following mathematical conventions\")\n",
    "\n",
    "print(\"\\n1D vectors are useful for:\")\n",
    "print(\"- Most PyTorch operations (default behavior)\")\n",
    "print(\"- Element-wise operations\")\n",
    "print(\"- When you don't need explicit matrix operations\")\n",
    "\n",
    "# Example: Stacking vectors\n",
    "samples = [\n",
    "    torch.tensor([1, 2, 3]),\n",
    "    torch.tensor([4, 5, 6]),\n",
    "    torch.tensor([7, 8, 9])\n",
    "]\n",
    "\n",
    "# Stack as rows (common for datasets)\n",
    "batch_matrix = torch.stack(samples, dim=0)\n",
    "print(\"\\nStacked as rows (batch):\")\n",
    "print(batch_matrix)\n",
    "print(\"Shape:\", batch_matrix.shape)\n",
    "\n",
    "# Stack as columns\n",
    "feature_matrix = torch.stack(samples, dim=1)\n",
    "print(\"\\nStacked as columns (features):\")\n",
    "print(feature_matrix)\n",
    "print(\"Shape:\", feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9d76eb",
   "metadata": {},
   "source": [
    "1. **`Tensor`:** Generally implies a structure with 3D or more dimensions.\n",
    "\n",
    "2. **`Matrix`:** Refers to a 2D structure, typically represented as an array or DataFrame with shape \\( (m, n) \\).\n",
    "\n",
    "3. **`Vector`:** Can have shapes \\( (n) \\), \\( (1, n) \\), or \\( (n, 1) \\).\n",
    "\n",
    "4. **`Scalar`:** Represents a single numeric value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbda44",
   "metadata": {},
   "source": [
    "### **Row vs. Column Vectors:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd744969",
   "metadata": {},
   "source": [
    "The key differences between `row and column vectors` are primarily about `shape` and how they `interact with matrix operations`:\n",
    "\n",
    "**Shape differences:**\n",
    "  - **1D vector**: `torch.Size([n])` - most common in PyTorch\n",
    "\n",
    "  - **Row vector**: `torch.Size([1, n])` - 2D tensor with 1 row\n",
    "\n",
    "  - **Column vector**: `torch.Size([n, 1])` - 2D tensor with 1 column\n",
    "\n",
    "**When row vectors are useful:**\n",
    "   - Representing single data samples (each row is an observation)\n",
    "\n",
    "   - Creating batches where you stack samples vertically\n",
    "\n",
    "   - Input to neural networks (batch dimension first)\n",
    "\n",
    "   - When you need explicit 2D structure for matrix operations\n",
    "\n",
    "**When column vectors are useful:**\n",
    "   - Traditional linear algebra operations following mathematical conventions\n",
    "\n",
    "   - Representing weight vectors in some optimization contexts\n",
    "\n",
    "   - When you need explicit column structure for matrix multiplication\n",
    "\n",
    "   - Academic/theoretical work that follows mathematical notation\n",
    "\n",
    "**Broadcasting implications:**  \n",
    "   Row vectors and column vectors have different broadcasting behavior. Adding a row vector `[1, 2, 3]` to a column vector `[[1], [2], [3]]` creates a 3×3 matrix due to broadcasting rules, which can be either useful or problematic depending on the intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d68ed05",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d23da6b",
   "metadata": {},
   "source": [
    "### **Angle Between Vectors:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89553104",
   "metadata": {},
   "source": [
    "The angle between two vectors is a fundamental geometric concept that measures the `\"spread\"` or `separation` between their directions in space. \n",
    "\n",
    "Mathematically, this angle is calculated using the dot product formula: **$cos(θ) = (u · v) / (|u| × |v|)$**, where $θ$ is the angle, $u · v$ is the dot product, and |$u$|, |$v$| are the magnitudes of the vectors. The angle is always measured as the smaller of the two possible angles between the vectors, ranging from $0°$ to $180°$ (or $0$ to $π$ radians).\n",
    "\n",
    "**The angle has intuitive geometric meaning:** when vectors point in the same direction, the angle is $0°$; when they're perpendicular ($orthogonal$), the angle is $90°$; and when they point in opposite directions, the angle is $180°$. \n",
    "\n",
    "In machine learning and data science, vector angles are crucial for measuring `similarity` - `smaller angles indicate more similar vectors`. This is used in applications like `document similarity` (where documents are represented as word vectors), `recommendation systems`, and `neural network attention mechanisms`. The cosine of the angle `(cosine similarity)` is particularly popular because it ranges from `-1 to 1`, making it easy to interpret: `values near 1 indicate high similarity, near 0 indicate orthogonality, and near -1 indicate opposite directions`.The angle between vectors is calculated using the dot product formula and has several important properties:\n",
    "\n",
    "**Key Mathematical Properties:**\n",
    "   - The angle $θ$ satisfies: $cos(θ) = (u · v) / (|u| × |v|)$\n",
    "\n",
    "   - Range: $0° ≤ θ ≤ 180°$ (or $0 ≤ θ ≤ π$ radians)\n",
    "\n",
    "   - The angle is always the smaller of the two possible angles between vector directions\n",
    "\n",
    "**Geometric Interpretation:**\n",
    "   - **$0°$**: Vectors point in exactly the same direction\n",
    "\n",
    "   - **$90°$**: Vectors are perpendicular (orthogonal)\n",
    "\n",
    "   - **$180°$**: Vectors point in exactly opposite directions\n",
    "\n",
    "   - **Acute angles $(< 90°)$**: Vectors point in generally the same direction\n",
    "\n",
    "   - **Obtuse angles $(> 90°)$**: Vectors point in generally opposite directions\n",
    "\n",
    "**`Practical Applications`:**  \n",
    "The angle concept is fundamental in data science and machine learning through **`cosine similarity`** $(cos θ)$, which ranges from $-1$ to $1$. This measure is scale-invariant, meaning it only considers direction, not magnitude. It's extensively used in document similarity (comparing word frequency vectors), recommendation systems (comparing user preference vectors), image recognition (comparing feature vectors), and neural network attention mechanisms. The closer the `cosine similarity` is to 1, the more similar the vectors are in direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9805f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# ANGLE BETWEEN VECTORS: \n",
    "\n",
    "def calculate_angle_between_vectors(u, v, return_degrees=True):\n",
    "    \"\"\"\n",
    "    Calculate angle between two vectors using dot product formula\n",
    "    \n",
    "    Args:\n",
    "        u, v: torch tensors representing vectors\n",
    "        return_degrees: if True, return angle in degrees, else radians\n",
    "    \n",
    "    Returns:\n",
    "        angle: float, angle between vectors\n",
    "    \"\"\"\n",
    "    # Calculate dot product\n",
    "    dot_product = torch.dot(u, v)\n",
    "    \n",
    "    # Calculate magnitudes\n",
    "    magnitude_u = torch.norm(u)\n",
    "    magnitude_v = torch.norm(v)\n",
    "    \n",
    "    # Calculate cosine of angle\n",
    "    cos_angle = dot_product / (magnitude_u * magnitude_v)\n",
    "    \n",
    "    # Handle numerical precision issues\n",
    "    cos_angle = torch.clamp(cos_angle, -1.0, 1.0)\n",
    "    \n",
    "    # Calculate angle in radians\n",
    "    angle_rad = torch.acos(cos_angle)\n",
    "    \n",
    "    if return_degrees:\n",
    "        angle_deg = angle_rad * 180 / math.pi\n",
    "        return angle_deg.item()\n",
    "    else:\n",
    "        return angle_rad.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e0760",
   "metadata": {},
   "source": [
    "**ANGLE BETWEEN VECTORS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "657dfcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGLE BETWEEN VECTORS - EXAMPLES\n",
      "==================================================\n",
      "Example 1 - Same direction:\n",
      "u = tensor([1., 0.]), v = tensor([2., 0.])\n",
      "Angle = 0.00°\n",
      "Cosine similarity = 1.0000\n",
      "\n",
      "Example 2 - Perpendicular:\n",
      "u = tensor([1., 0.]), v = tensor([0., 1.])\n",
      "Angle = 90.00°\n",
      "Cosine similarity = 0.0000\n",
      "\n",
      "Example 3 - Opposite direction:\n",
      "u = tensor([1., 0.]), v = tensor([-1.,  0.])\n",
      "Angle = 180.00°\n",
      "Cosine similarity = -1.0000\n",
      "\n",
      "Example 4 - 45-degree angle:\n",
      "u = tensor([1., 0.]), v = tensor([1., 1.])\n",
      "Angle = 45.00°\n",
      "Cosine similarity = 0.7071\n",
      "\n",
      "Example 5 - 3D vectors:\n",
      "u = tensor([1., 2., 3.]), v = tensor([4., 5., 6.])\n",
      "Angle = 12.93°\n",
      "Cosine similarity = 0.9746\n"
     ]
    }
   ],
   "source": [
    "print(\"ANGLE BETWEEN VECTORS - EXAMPLES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Example 1: Same direction vectors\n",
    "u1 = torch.tensor([1.0, 0.0])\n",
    "v1 = torch.tensor([2.0, 0.0])\n",
    "angle1 = calculate_angle_between_vectors(u1, v1)\n",
    "print(f\"Example 1 - Same direction:\")\n",
    "print(f\"u = {u1}, v = {v1}\")\n",
    "print(f\"Angle = {angle1:.2f}°\")\n",
    "print(f\"Cosine similarity = {torch.dot(u1, v1) / (torch.norm(u1) * torch.norm(v1)):.4f}\")\n",
    "\n",
    "# Example 2: Perpendicular vectors\n",
    "u2 = torch.tensor([1.0, 0.0])\n",
    "v2 = torch.tensor([0.0, 1.0])\n",
    "angle2 = calculate_angle_between_vectors(u2, v2)\n",
    "print(f\"\\nExample 2 - Perpendicular:\")\n",
    "print(f\"u = {u2}, v = {v2}\")\n",
    "print(f\"Angle = {angle2:.2f}°\")\n",
    "print(f\"Cosine similarity = {torch.dot(u2, v2) / (torch.norm(u2) * torch.norm(v2)):.4f}\")\n",
    "\n",
    "# Example 3: Opposite direction vectors\n",
    "u3 = torch.tensor([1.0, 0.0])\n",
    "v3 = torch.tensor([-1.0, 0.0])\n",
    "angle3 = calculate_angle_between_vectors(u3, v3)\n",
    "print(f\"\\nExample 3 - Opposite direction:\")\n",
    "print(f\"u = {u3}, v = {v3}\")\n",
    "print(f\"Angle = {angle3:.2f}°\")\n",
    "print(f\"Cosine similarity = {torch.dot(u3, v3) / (torch.norm(u3) * torch.norm(v3)):.4f}\")\n",
    "\n",
    "# Example 4: 45-degree angle\n",
    "u4 = torch.tensor([1.0, 0.0])\n",
    "v4 = torch.tensor([1.0, 1.0])\n",
    "angle4 = calculate_angle_between_vectors(u4, v4)\n",
    "print(f\"\\nExample 4 - 45-degree angle:\")\n",
    "print(f\"u = {u4}, v = {v4}\")\n",
    "print(f\"Angle = {angle4:.2f}°\")\n",
    "print(f\"Cosine similarity = {torch.dot(u4, v4) / (torch.norm(u4) * torch.norm(v4)):.4f}\")\n",
    "\n",
    "# Example 5: Higher dimensional vectors\n",
    "u5 = torch.tensor([1.0, 2.0, 3.0])\n",
    "v5 = torch.tensor([4.0, 5.0, 6.0])\n",
    "angle5 = calculate_angle_between_vectors(u5, v5)\n",
    "print(f\"\\nExample 5 - 3D vectors:\")\n",
    "print(f\"u = {u5}, v = {v5}\")\n",
    "print(f\"Angle = {angle5:.2f}°\")\n",
    "print(f\"Cosine similarity = {torch.dot(u5, v5) / (torch.norm(u5) * torch.norm(v5)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e884441",
   "metadata": {},
   "source": [
    "**COSINE SIMILARITY FUNCTION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81f43c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH PROCESSING - ANGLES BETWEEN MULTIPLE VECTORS\n",
      "==================================================\n",
      "Reference vector: tensor([1., 0.])\n",
      "\n",
      "Angles with reference vector:\n",
      "Vector 1 tensor([1., 0.]): Angle = 0.00°, Cosine similarity = 1.0000\n",
      "Vector 2 tensor([0., 1.]): Angle = 90.00°, Cosine similarity = 0.0000\n",
      "Vector 3 tensor([-1.,  0.]): Angle = 180.00°, Cosine similarity = -1.0000\n",
      "Vector 4 tensor([1., 1.]): Angle = 45.00°, Cosine similarity = 0.7071\n",
      "Vector 5 tensor([-1., -1.]): Angle = 135.00°, Cosine similarity = -0.7071\n"
     ]
    }
   ],
   "source": [
    "# COSINE SIMILARITY FUNCTION: \n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    return torch.dot(u, v) / (torch.norm(u) * torch.norm(v))\n",
    "\n",
    "# BATCH PROCESSING:\n",
    "\n",
    "print(\"BATCH PROCESSING - ANGLES BETWEEN MULTIPLE VECTORS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create multiple vectors\n",
    "vectors = torch.tensor([\n",
    "    [1.0, 0.0],    # Vector 1\n",
    "    [0.0, 1.0],    # Vector 2\n",
    "    [-1.0, 0.0],   # Vector 3\n",
    "    [1.0, 1.0],    # Vector 4\n",
    "    [-1.0, -1.0]   # Vector 5\n",
    "])\n",
    "\n",
    "reference_vector = torch.tensor([1.0, 0.0])\n",
    "\n",
    "print(\"Reference vector:\", reference_vector)\n",
    "print(\"\\nAngles with reference vector:\")\n",
    "for i, vec in enumerate(vectors):\n",
    "    angle = calculate_angle_between_vectors(reference_vector, vec)\n",
    "    cos_sim = cosine_similarity(reference_vector, vec)\n",
    "    print(f\"Vector {i+1} {vec}: Angle = {angle:.2f}°, Cosine similarity = {cos_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855518d",
   "metadata": {},
   "source": [
    "**VECTORIZED COSINE SIMILARITY:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "543d5682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch cosine similarities: tensor([ 1.0000,  0.0000, -1.0000,  0.7071, -0.7071])\n"
     ]
    }
   ],
   "source": [
    "# VECTORIZED COSINE SIMILARITY: \n",
    "\n",
    "def batch_cosine_similarity(reference, vectors):\n",
    "    \"\"\"Calculate cosine similarity between reference and batch of vectors\"\"\"\n",
    "    # Normalize reference vector\n",
    "    ref_norm = reference / torch.norm(reference)\n",
    "    \n",
    "    # Normalize all vectors\n",
    "    vec_norms = vectors / torch.norm(vectors, dim=1, keepdim=True)\n",
    "    \n",
    "    # Calculate cosine similarities\n",
    "    cos_similarities = torch.mm(vec_norms, ref_norm.unsqueeze(1)).squeeze()\n",
    "    \n",
    "    return cos_similarities\n",
    "\n",
    "# Batch calculation\n",
    "batch_cos_sim = batch_cosine_similarity(reference_vector, vectors)\n",
    "print(f\"\\nBatch cosine similarities: {batch_cos_sim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c4f654",
   "metadata": {},
   "source": [
    "**PRACTICAL APPLICATIONS OF ANGLE BETWEEN VECTORS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79cdc045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRACTICAL APPLICATIONS\n",
      "==================================================\n",
      "Application 1: Document Similarity\n",
      "------------------------------\n",
      "Document word count vectors:\n",
      "Document 1: tensor([3., 2., 1., 0., 1.])\n",
      "Document 2: tensor([2., 3., 1., 1., 0.])\n",
      "Document 3: tensor([0., 0., 0., 5., 5.])\n",
      "\n",
      "Pairwise document similarities:\n",
      "Document 1 vs Document 2: Cosine similarity = 0.8667, Angle = 29.93°\n",
      "Document 1 vs Document 3: Cosine similarity = 0.1826, Angle = 79.48°\n",
      "Document 2 vs Document 3: Cosine similarity = 0.1826, Angle = 79.48°\n",
      "\n",
      "Application 2: User Preference Similarity\n",
      "----------------------------------------\n",
      "User preference vectors:\n",
      "User 1: tensor([5., 3., 0., 1., 4.])\n",
      "User 2: tensor([4., 2., 0., 2., 5.])\n",
      "User 3: tensor([1., 5., 4., 5., 1.])\n",
      "\n",
      "User similarity for recommendations:\n",
      "User 1 vs User 2: Cosine similarity = 0.9602, Angle = 16.22°\n",
      "User 1 vs User 3: Cosine similarity = 0.4924, Angle = 60.50°\n",
      "User 2 vs User 3: Cosine similarity = 0.5024, Angle = 59.84°\n"
     ]
    }
   ],
   "source": [
    "# PRACTICAL APPLICATIONS:\n",
    "\n",
    "print(\"PRACTICAL APPLICATIONS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Application 1: Document similarity\n",
    "print(\"Application 1: Document Similarity\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Simulate document word count vectors\n",
    "doc1 = torch.tensor([3.0, 2.0, 1.0, 0.0, 1.0])  # [word1, word2, word3, word4, word5]\n",
    "doc2 = torch.tensor([2.0, 3.0, 1.0, 1.0, 0.0])\n",
    "doc3 = torch.tensor([0.0, 0.0, 0.0, 5.0, 5.0])\n",
    "\n",
    "docs = [(\"Document 1\", doc1), (\"Document 2\", doc2), (\"Document 3\", doc3)]\n",
    "\n",
    "print(\"Document word count vectors:\")\n",
    "for name, doc in docs:\n",
    "    print(f\"{name}: {doc}\")\n",
    "\n",
    "print(\"\\nPairwise document similarities:\")\n",
    "for i, (name1, doc1) in enumerate(docs):\n",
    "    for j, (name2, doc2) in enumerate(docs):\n",
    "        if i < j:  # Avoid duplicate comparisons\n",
    "            similarity = cosine_similarity(doc1, doc2)\n",
    "            angle = calculate_angle_between_vectors(doc1, doc2)\n",
    "            print(f\"{name1} vs {name2}: Cosine similarity = {similarity:.4f}, Angle = {angle:.2f}°\")\n",
    "\n",
    "# Application 2: Recommendation system\n",
    "print(f\"\\nApplication 2: User Preference Similarity\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# User ratings for different items (movies, products, etc.)\n",
    "user1 = torch.tensor([5.0, 3.0, 0.0, 1.0, 4.0])  # [item1, item2, item3, item4, item5]\n",
    "user2 = torch.tensor([4.0, 2.0, 0.0, 2.0, 5.0])\n",
    "user3 = torch.tensor([1.0, 5.0, 4.0, 5.0, 1.0])\n",
    "\n",
    "users = [(\"User 1\", user1), (\"User 2\", user2), (\"User 3\", user3)]\n",
    "\n",
    "print(\"User preference vectors:\")\n",
    "for name, user in users:\n",
    "    print(f\"{name}: {user}\")\n",
    "\n",
    "print(\"\\nUser similarity for recommendations:\")\n",
    "for i, (name1, user1) in enumerate(users):\n",
    "    for j, (name2, user2) in enumerate(users):\n",
    "        if i < j:\n",
    "            similarity = cosine_similarity(user1, user2)\n",
    "            angle = calculate_angle_between_vectors(user1, user2)\n",
    "            print(f\"{name1} vs {name2}: Cosine similarity = {similarity:.4f}, Angle = {angle:.2f}°\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc38be57",
   "metadata": {},
   "source": [
    "**VISUALLIZING THE ANGLE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03fe54c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAJOCAYAAAByYpf8AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAATkVJREFUeJzt3Qm81PP+x/HPaS9aVSrttqKEKBJKKEtEwuVSpD9uIWUpW7IlXHuy3nIvXctNWS7RpQUJ1bWUikghnBJttJ75P97f7m/OzJw558xZ5zszr+fjMXLmzJn5zXd+M7/3fL7f7++bFQqFQgYAAOCZCsneAAAAgHgIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpADJay5YtbcCAAeY7baO2FcgkhBTAA6eccorVqFHDNmzYkO9tzj33XKtSpYr98ssvpfrYd9xxh02dOrVU7zOd/fbbb1atWjXLysqyxYsXJ3tzgLRGSAE8oADyxx9/2JQpU+L+/vfff7eXX37ZevXqZbvttlupPjYhpWhefPFFF1AaNWpkzz77bLI3B0hrhBTAk0pKzZo1bdKkSXF/r4CyadMmF2ZSgbY1XT3zzDN24okn2p/+9Kd8Xy8ApYOQAnigevXqdvrpp9vbb79t2dnZeX6vg6FCjMJM0OUwdOhQa9asmVWtWtX22msvGzt2rOXk5ET9nX5+4IEHrH379q6LokGDBq4aM2/ePPd7VQQUKJ5++mn3/7pEjs/473//ayeccILVqlXLdt11V+vRo4fNnTs36jEmTpzo/m7WrFn2l7/8xRo2bGhNmzZ1v1P3lbZTYym0nfrdcccdZwsWLCiwPVasWOHua99993Vto+pRv3797Ntvv4372O+//74NGzbMPb9ddtnFTjvtNFu9enXUbbXg+2233ea2TV1r3bt3t0WLFllRrFy50t599107++yz3WX58uU2Z86cPLfr1q2btWvXzr744gv3OHq8PfbYw+666664z1Wvq7Zb7XPllVfam2++6Z7XzJkzC9wevb7333+/7b///u713X333e3iiy+2X3/9tUjPC/BVpWRvAICdVCVRWHjhhRdsyJAh4evXrl3rDlr65q4Dtrp+jj76aPvhhx/cAal58+buQDly5Ej78ccf3UErMHDgQHcgV9C46KKLbPv27e4gq6BxyCGH2D/+8Q93fadOnez//u//3N/sueee7l8dwI888kgXUK655hqrXLmyPfbYY+4ArEDSuXPnqO1XqFBIuOmmm8KVlEsuucT+9a9/ueez3377ufE07733nhvLcfDBB+fbFh9//LF7TgoCChUKJ+PHj3ePrQO/DvqRLrvsMqtbt66NGjXK3VZtoMd8/vnnw7fRdimkqAqii4LS8ccfb1u3bk34NfrnP//pwsTJJ5/sXgu1lbp8unTpkue2CgoKhAqfZ555pmuHa6+91gVGvR6idjrmmGPc63bFFVe4LiQF0hkzZiS0PXr99fpecMEFdvnll7vQ9PDDD7twqeCm1wxIaSEAXti+fXuocePGocMPPzzq+kcffTSkt+qbb77pfr711ltDu+yyS+jLL7+Mut2IESNCFStWDK1cudL9/M4777i/u/zyy/M8Vk5OTvj/dV/9+/fPc5s+ffqEqlSpEvr666/D161atSpUs2bN0FFHHRW+bsKECe5xunbt6p5DpNq1a4cGDx5c5Lb4/fff81z3wQcfuMf5+9//nuexjz322KjndOWVV7q2+O2339zP2dnZ7rmcdNJJUbe77rrr3N/He/7xtG/fPnTuuedG/X39+vVD27Zti7rd0UcfnWdbt2zZEmrUqFGob9++4ev++te/uttNnTo1fN0ff/wRatOmjbt+xowZ4eu1jS1atAj//O6777rbPPvss1GPPW3atLjXA6mI7h7AExUrVnSVgw8++CCqW0PfrFXGV1dLMHBTFQ5VDtasWRO+HHvssbZjxw6bPXu2u93kyZNdl4GqC7F0fUF0P2+99Zb16dPHWrduHb6+cePGds4557hqyPr166P+ZtCgQe45RKpTp459+OGHtmrVqiK1haoUgW3btrkKjLq0dH/xuopUBYp8TmofPQd1pch//vMfVzFRxSXyduqKStRnn31mn3/+uatoBfT/antVumKpe+zPf/5z+GfNzFLF6ptvvglfN23aNNcNFHTjibpt1JaF0X5Qu3Zt130WuR907NjRPXai1RjAZ4QUwCPBwNhgQOb3338fHgMRBICvvvrKHdzUtRJ5UUiRYEzL119/bU2aNLF69eoVeTs0nkPdShoTEqtt27ZuLMR3330XdX2rVq3y3FZjMBYuXOjGzugAffPNN0cdpPOjmU7qngnG3NSvX989R43FWbduXZ7bq8srkgKcBGMzgrCy9957R91O9xncNpEBs+rqUWhbtmyZuyhQaLxNvFk+6qaKDYN6rMjxItoudRnF3k6BrDDaD9QWGscSuy9s3Lgx7tgmINUwJgXwiL4Ft2nTxo19uO6669y/GvAZOatHAUHfnjVOJJ599tnHkiGy+hHQWAxVNTS1WpWZu+++2w3wfemll8LjMuJRxWPChAmu0nH44Ye7ioEO5AprsYODJbaCE1DblQbdj14LjSHR2JpYCgQKBqpglNc2qR0UUPKbBq2wAqQ6QgrgGQWSG2+80XUvqKKib/+HHnpo+Pf65q0DYlA5yY9up24IDbwtqJoSr+tHBzgNTl26dGme3y1ZssQqVKjgqhyJUBeRBtXqooO5BszefvvtBYYUDTLt37+//fWvfw1ft3nzZldJKY4WLVqEqw+R3VeqGCUyE0YDhVXVuuWWW1wlKZL+Xt1NOtdMZPdOotulgcAKLpGvg6o0hdHrq26sI444Im5ABNIB3T2AZ4Kqibo7PvnkkzznRlF1QuNW4o2D0EFcM3ikb9++7uA3evToAr/Nqwsj9uCvKoBmvuj8LJHjY37++WcXnLp27epm/RREY0Jiu2b0zV9dUFu2bCnwb/X4sRWHhx56yN1ncSjQaaaL7iPyfiNnQiXS1XP11VfbGWecEXXR+BEFyeKc2K1nz55ultYrr7wSFcaeeOKJQv9W+4Ha49Zbb83zO+0DxQ10gE+opACe0dgOTWlVQJDYkKIDpQ5qmgarc5qoi0jdEBrUqQqEQoXGcOj8HOedd549+OCDroKg6bDqItAYF/0umOasv9c38nvvvdcFCD2+phdruu706dNdIFEVpFKlSm4KsgJGvPN9xNI5UjQuQwfyDh06uK4QPY6mF0dWSOLRc9P0aHXzqHtFoUx/W9yz7aoydNVVV9mYMWPcfWsKsqbpvvHGG66tCqLnq0HI6mLTGJR4NPBV56NRpUhBLFGaQqwpwxqAqynIqjop7ASPU9AAZ01D19/rOSnMKlQqiOm11qBabY/aHkhpyZ5eBCCvcePGuWmknTp1ivv7DRs2hEaOHBnaa6+93NRaTYPt0qVL6J577glt3bo1fDtNCb777rvdlFbdrkGDBqETTjghNH/+/PBtlixZ4qYUV69ePc903AULFoR69uwZ2nXXXUM1atQIde/ePTRnzpyobQmmAX/88cdR12vK7dVXXx3q0KGDm7asqc76/0ceeaTQ5//rr7+GLrjgAve89NjaBm2npuBGbl9+j62pu7FTeHfs2BEaPXq0m+at59qtW7fQwoUL89xnrMmTJ7v7euqpp/K9zcyZM91tHnjggfAU5P333z/P7WKnEcs333zjpkZrm/T6DB8+PPyYc+fOLfBv5fHHHw917NjR/b3aWdOkr7nmGjddHEh1WfpPsoMSAMCiuqF05lmNg9EUZSBTEVIAIIk03Tpy4KvGpBx00EFuvMmXX36Z1G0Dko0xKQCQRDptvs7zcuCBB7qBxhqkqxlUrLAMEFIAIKk0w+fJJ590oUTVEw0Ufu655+yss85K9qYBSUd3DwAA8BLnSQEAAF4ipAAAAC8RUlDudIIqLTSHsqETtgVnnU01OhGd9o+JEyeaj7p16+YupUkLFOqkfIGZM2e6NtC/pUmPoccCUgkhJYM98sgj7sNQZxdFXtu2bXODGNVG99xzT9yDabyLBj0mQqct15ovOhuqTrmus8AuWLAg7m11hlmteaMzkWomyKhRo+IGEZ0JVqer1+Xaa6+1ktKZTLUeTbAasdYA0inmtfhfcU9RDz9olWt9WSjtMFQWoVv7tc6ErP3/gAMOcIs9JkKBMr/3qc7OW5z3WVHu8/nnn3fvHy2boN+XdsDNBMzuyWCaTaBvVh999JFb0CyR5eEzidZ5WblyZYG30enMdYr1SFq1N5EP3pNOOsk+/fRTd5p7nZpdoVEfYvPnz3cfagGdur1Pnz7ud9omnf5ep6zXKdjHjx8fvt3777/vTpGu09trcUCtoqxT3muNl+LQjJNLLrnEdt99d3d6fW2TTnX/9ttv28CBA+3HH390j1GatOCezhsS7wDiA63kXNq0iKMWbCxrWg8ocgVphZRgXSefD57XX3+93XnnnW6NJC20qeUizjnnnPCq2IX97UUXXRR1nZaQ0H6tZQQiJfo+K8p96u/0ftZ2//LLLyVohQyW7FPeIjl0Km69/C+99JI7FffNN99cbo+txx01alTIZz///HOodu3aoVtuucVtr04tH2n58uVxr0/U888/7/7+xRdfDF+XnZ0dqlOnTuhPf/pT1G33228/dzr5bdu2ha+7/vrrQ1lZWaHFixeHr9O2DB06NPzz/fffHxoyZEixtu+DDz4IVaxYMdS1a9fQ+vXr8/xep6HXKelR+uKd0r8kNm7cGPf61atXe/9e/P7770OVK1cODR48OHxdTk5O6Mgjjww1bdrULftQVP/4xz/c83722WeL9T4ryn2uXLnSLccgWiZByyWgaOjuyeAqSt26dd23eS1CFu/EUUGXhro6Hn/8cbc0vEr++lagReJiaVEzdY+oVNquXTubMmVKwv3gWgn2wgsvdN/a9Rj777+//e1vf7NkGTFihO27776uVFsYfYvaunVrke5fCwHquepEXgF1+6jqoW+KwSrBX3zxhbuoW0gL/AW04J/ynu4n0Lp1a1eunjt3rqvQ6DWNrMgUhb5h67XXfdSsWTPP7w855JCocRRqg+HDh4e7hdR22m9iz3AQLFhYp04dt+CgbhdZjYk3JkWPo9tqH9E3Xf1/sGBgbJeTKgU6pbz2H+2HamMtwvfrr78W+px/+uknu+CCC9yiiHoOWuzv1FNPjVoFOnZMSjB+5IUXXnBtplPYq730ntKJ2fQ6Dh061C06qO3W/ceuAB07JiUeLQrZr18/1wWhbVM767T5qjpFCtrq66+/dhU+bUuwQGXke1HPSW0Y+VoHY8XUlaf/1wKMse644w63QrVei/Kg94K6XbW/B7Rtl156qVsyQAtPFpVW8Vb3ql7bQFHeZ4nep+h1Ko8qWTqjuydD6eCjA2SVKlVcl4XKkgoeCiDx3oAq8+vDXh8Q6h/W337zzTfhsvy///1vd/Kp9u3buy4HHRTUJZDIuiM///yzHXbYYe6+tTKvPjxVetXfr1+/3n3IF0QHA32QFUYHLX2AF0bdX08//bS99957Ba5CG3zAq7tGt1PXyu23356n5BuPDgDq+479AOvUqZMLhDodutoyOFAoFETSasU6mEYeSHQA18rBQXeTxrjoQ7eo1A2gLp2jjjrKHRQLow9xrQI8Y8YM95rpzKlvvvmmaxcdzO677z53u0WLFrkViDWm4JZbbnEHW3UzqpuqMAojOumZxk8p/GhFZK2krOCsA1ZA+6gCjsLA5ZdfbsuXL3erDKud9DgFdSP17dvXbeNll13mDuYq8ytUqcuvsKCtfV6ntle41XNSd4EeS6+v3gs6+Cs8ats0tuKmm26yotAXAL0ueq5aCVr7qB5DB2r9LpLGUKitFAbVVur6i6X3mN7zur/TTjstHJb12mj7Bg8e7D4jdHr+SLpOIa2g97Xei3pPJkJjnAo6iOt108G/bdu2ed4nwe/1PBO1evVq95rqs0r3G/k4ib7PEr1PlJIiVl6QBubNm+dKk9OnTw+XT1U6veKKK+J2aey2226htWvXhq9/+eWX3fWvvvpq+DqtvKr70Oq8sSvDxq7cGltiHjhwoFuZds2aNVG3O/vss12Xy++//17g81EJVfdZ2KWglW4DagutPBx0ueTXrbNixYrQ8ccfHxo/fnzolVdecV0rzZs3D1WoUCH02muvFfo4WhH4wgsvzHP9v//9b/d406ZNcz/rcfWzysaxDj300NBhhx2W5/ovvvgi9Omnn7rnUhz6Wz1m7P6Qn6lTp7rb33bbbVHXn3HGGa5UvmzZMvfzfffd526nbob8BO0d2ZWk103Xqest0kEHHeRW/w28++67cUvuast418euupxI9532tciSfdA1065du6jVp7X/6LlrxelIhx9+eJ73Q+wqzPG6e+K9B8aMGeMeQ/tibFuNGDEiz+1jV1EuqLtH29+kSZNwV0WwInbsaxNPsP2JXPR6F0SrQ7du3TrP9Zs2bcr3eRbkoYcecn/3+uuvR11fnPdZYfcZi+6e4qGSkoH0bUhlcH3TFlUB9C1Aa4bo26nKuZH0O3UNBY488kj3ryopsmrVKjfITGX7yErF0Ucf7aoBqobkR5ll8uTJrptD/79mzZrw7/RtUDNlNOPliCOOyPc+tM2JlPP1ragw+qar51JYeVcVBlULImlwqbq71O2hbrSCqEyvSkK8ak/w+8h/87ttvLaN/dZZVMF9xuvmief11193+4wqF5HUDmpHVcVUIVMXT1DCV6WjqGVwDUyMpP1QlaOAKgq1a9e24447Lmo/UoVL+6UqPRpwGY+qIKoqqvtG1aDI/T0R559/flSVRhUfzUBRF2YkXf/ggw+6akdkt0JhIhcgVNea9osuXbq494y+5cdWvCKrS8Wh56PtV5v16NEj/Lmh7VDFqSAdOnRwlYVENGrUqFTeJ4lSVVhVJO0jsY9T1PdZYfeJ0kFIyTAqm+vAr4CiUnjkh6cO9irzx3ZXxH4ABh/gQTBYsWKF+zfe7CBdl9+02qBUqqm46uLQJR6V3Quig1Bp0AfRyJEjXTeF+pKLSqVrHXw1E0FleJWJ86MP+9ixCcEKuMHvI//N77aRB6/SounLoi6+ROj1VwCMDTVBWAr2D4VdzRjSzAh1i+jgp24Gjd8oLLDoQBGMoYjcDyPD6VdffeW6GTT+o6j7kQ5OY8eOdcFKAV7dj+qa0sG6sANpvPeIwpLE7ke6XuNmtJ3qtkmUupzURaQxR7GBPLZrReGnoH0vETrgakyOgoleJ22zQovGXBQWXvW6aJp6aUj0fZIIfanSGBYF5tiAWNz3WUH3idJBq2aYd955x00dVVCJdz4PfSjFhpTYykqgNJZ9CqZEaoBq//79495G/eQFWbt2bUIDV/VBExw84lH/ve5HB9NgsKTChujAoOt0MNY37vwEByVtU0EHCh0A9DrECq4Lqj66XXB97AFP1wV986VJwVIfuKoolSa1/+zZs923c41hmjZtmjuPxDHHHOOm9ua3n0lBv4vclxRQ8ls9ODbkxNLYp969e9vUqVNdlezGG290Y030nokdm5Ho9pXGe0dfLBQatE/p3Ddt2rRxYx803keDYSOnFQeBq6SDNbXdqjpp2rKmxms8jyqmiQwk13tI25oIvSYFvbba/7W/qL0ix4fFvk8SoYqHBAOJYx+nOO+zgu4TpYOQkmH0Aa4P8nHjxuX53UsvveRm5Dz66KNF+oaic1uIBgzGindd7IeUvpnpg7i43770bXzWrFmF3k4hqKAzmerbqsKIZobEm9Wgi0rrGhian6ALrLADou5DMzZ0gIk8oHz44YduoOM+++wTvp3Mmzcv6oNSBwwFqOIMjC2MHl/BQQfn7777rtCqkl5/DWRV5SXyW/aSJUvCvw/oueqbuS46n4vaVOed0IGopN++NYhW26GuweJWmHQfqqboosqM2l8VRnWFJovCogZSazC3KjuBRLtU8lPYoHA9lp77q6++6rrstE+rC7Ywc+bMCXclF0bV3IIGJav9VX1bvHix60qNfJ8Ev0+UAoVeX1XJ4j1Ocd5nBd0nSgchJYOo31VBRFMZVWKPpW8lKumqpFyUZeL1d5py/Pe//911lwTjUhQc9AEbeZCKpW9R6uPWm33hwoXufmK7gwo74JfWmBSNqdAMmdguAs0Y0TdWlbo18yG/7dI3W02bVuUn+GYWfBNTSV4fZsG4BbW/xmvo9QheC42j0LgKfZsP+sYVmPTNWV1h2o7gW6dmZuggE+91LA0606a6/jTO5rXXXsszK0onqNLrpeCnqa7aPs2i0esf0KwebeMJJ5zgfta3a3WJxTs4xCuzF5XGNelb/6233urCTySNAdm4cWN4XEwszZxRgArGOoheL4Wu0ti2kghe88jqi/7/gQceKNH9BrN+1N0aj/ZjXRQSNDNJr3UiXRqlOSZF7zlNtdbrqv0reO76IqUZRhqXU9D7LKAvFwo6qo7FU5z3WWH3idJBSMkgCh/6tqvpovHo24AOvKq2FCWkiA4K+kDRt1iNy1Bo0IeKQocODgXRGA59k9a4GJ1VUt+YdEDTWBZ9My6sdFxaY1I0JViXSEG3jz7EIgPMNddc485FoYqAwo9u99hjj7lBjbEHDx249S048lujPvTU3mornZ8hOOOsKkrBWUADd999t3vN1A2nM2wqHKhtNbajqINkNX1U4bGw7gZ9+KvapvNE6MM78oyzGlyqfUln4xSFKn1zVkVE7aCDlLpvNEBWXSg6aIimHau7R4OKFVwVAPWc1S1WlGmk+dFAbR1g1EWj0/mrvXSwUkVE4U+vS36hTpUKvZYKOtr/dDBWVVHT4ws7q2lZU/urDXVeGAVhjRnSYPNEgnlBVG3Sc1WXmyp3CpB6v0Z+UVA1RY8riXT1lPaYFO0b2of0HtDUZp0iQd1xqkLqcyqyqyje+ywQdAEW1C1T1PdZIvep/V2X4IuNPh+C942m+OuCQhRzVhBSUO/evUPVqlVz0/fyM2DAAHeGR00HLuisqvGmLj733HOhNm3ahKpWreqmZGpqbt++fd11hf2tzvCqs0o2a9bMPX6jRo1CPXr0CD3++OOhZMqvDSZNmhQ66qij3Nl6K1WqFKpfv37otNNOC82fPz/PfQTTQmOnW2pat6Zfa4p3jRo13PREnck1nilTpoQOPPBA17aa6n3DDTdETXlNlKbsqm0TpedzzjnnuOmoel3q1q3rXpenn346anqqpp5feeWV4dvtvffers0ip0G//fbboVNPPdXdpkqVKu5fTXX98ssvC52CrCnbsbQPxfsI0z6j51m9evVQzZo13fT4a665JrRq1ap8n6f2d+1/2lf1WJr63rlz59ALL7yQ0BTkyDMHi7Zf18e+nsE2R07DTmQKsqaVH3vssaFdd93V7WuDBg0KTxVPpK2C38VOf54zZ45rK70e8d6XP/74ozvz8D777BNKFu1nd9xxh9t2baem8j7zzDMJv8/093vssUfo4IMPLvSxEn2fJXqfwesd7+LzmX59kqX/FBZkgOJSOV/VmZL2n6PkVAXRt2WdkVUn6wIKoy5IdV1qZhHdGkgGzteLUqFSbOxqoeoW0OnZfV68LJOo7Kx+fHWpAYnQQHN1Qaq7D0gGKikoFRqLoH5o9VtrjIZmdmhwm6b8qm+3KOeEAJBcmtmlsVKqnmi8kQZ4A8lASEGp0Kh6TdPT+RQ0QEzncdBARA2KDQZOAkgNqn5qKrEGwmv6dSJrcAFlgZACAAC8xJgUAADgJUIKAADwUkadzE2nINdpjnUWycJOCQ0AAEqfRpnolAiaZFHYOlMZFVIUUIqzui0AAChdWhussBW7MyqkBIufqWGC5eh9q/QEa8KUdBXTVEdb5KIt8raH1nvSqeEzvT3YN3LRFqnTFuvXr3cFg8gFSfOTUSEl6OJRQPE1pGzevNltm487VnmiLXLRFnnbQ2vr0B7sG5Foi9Rri0SGXfi79QAAIKMRUgAAgJcIKQAAwEsZNSYFAFKBFvXTop2JjD3Q7TT+wOexB+WBtvCrLapUqVIqj01IAQCPzh/x008/2W+//Zbw7XVA0jknMv3cT7SFX22hgNKqVSsXVkqCkAIAnggCSsOGDa1GjRqFHmB0MNq+fbub7cSBmbbwpS2CE6f++OOP1rx58xJtAyEFADzp4gkCym677ZYSByOf0BZ+tYXO0aKgou2oXLlyse8nszvuAMATwRgUVVCAVFflf908Ct8lQUgBAI9kehUA6SGrlPZjQgoAAPASIQUAgHJy1FFH2aRJk6IqDrrUqVPHfDRz5szwNvbp0yd8/WGHHebWzyprhBQA8Jwq5/EuFSpkWZUqld2/+d2mOJdUMGDAgKiDZip45ZVX7Oeff7azzz476voJEybYl19+Gf75vffesyOOOMINoK5evbq1adPG7rvvvhI//qJFi9zinC1btnSh4/777y/0b7p06eJm6Zx55plR199www02YsQIN5OnLBFSAAAo45k28uCDD9oFF1yQ5yRnqqJoVldgl112sSFDhtjs2bNt8eLFLhDo8vjjj5doW37//Xdr3bq13XnnndaoUaOEB8DqtgpLkU444QR3HpY33njDyhIhBQBQIvpmHvut/MADD7Sbb765TB5P9/v000/byy+/HO6KULeEfPfdd+5bvw789erVs1NPPdW+/fbbPBWYe+65xxo3buyqFYMHD446w+8jjzxie++9t1WrVs123313O+OMM8K/27Jli11++eUuVOj3Xbt2tY8//jhP94gO3h07drSqVau6ysjq1avtnXfesd69exf6/A466CD705/+ZPvvv79r2z//+c/Ws2dPe/fdd0vUboceeqjdfffdrpKj7SqJihUr2oknnmjPPfeclSVCCgCg3D377LO26667FnjJ76B81VVXuSDSq1cv1xWhi7olFDR0Xc2aNd3fvv/+++5+dN3WrVvDfz9jxgz7+uuv3b8KOxMnTnQXmTdvngsht9xyiy1dutSmTZvmxpEErrnmGjcWQ3+3YMEC22uvvVyAWLt2bdQ2qitEFQtVQg444AAXVDS9vG3btkVuq//+9782Z84cO/roo80nnTp1KnFwKgwncwMAlLtTTjnFOnfuXOBt9thjj7jXK3io+0FVjaDbQt0qCg4aI/Hkk0+Gp8BqvIeqKqpwHH/88e66unXr2sMPP+yqARrvcdJJJ9nbb79tgwYNspUrV7rulpNPPtmFnRYtWrjKhmzatMnGjx/vAo26O+SJJ56w6dOn21NPPWVXX311eBsVco477rjwzytWrHBVmaKsZ9O0aVNXgVF3kapHF110kfmkSZMmrnKlNi+rNYIIKQCAcqcAoEtp+vzzz23ZsmV57lcL7alyElA3igJKQN0++ltRsFAw0dgNVWB0Oe2001wVRPehao0GtQZ0NlVVFFQxiXTIIYdE/fzHH3+47qGiePfdd23jxo02d+5cV5lR1UbdQL5QUFRAUViMHbNSWggpAIAS0bdoVTIiFbaKs7p7Lr744gJvo3EdRx55ZMLboQO6xoHovuOdpj0Qe5p2VV2CWSoKOOrGUeXlrbfesptuuslVMSLHnSRC1ZhI9evXt19//bVI99GqVSv3b/v27d2sIG2HTyFFXVx6nmUVUISQAgAoEQUAjQsJrF+/3pYvX15m3T3BrJPYU66rW+bFF190g1pr1aplxaU1b4499lh3GTVqlOsu0qBXjT3R42qsi6otQRhTgBk6dGiB96lt0wKSCirqbiqqnP9VLHyycOHCcFdYWSGkAABK5JhjjnHjNDRzRQd0VR8iu1PKortHs17efPNNN7hVM3QUSlRluPfee92MHo0J0ZgOjQV56aWX3IBX/VyY1157zb755hs3WFZh4vXXX3cBYd9993VVg0svvdSNPdHMIa3we9ddd7mpvQMHDizwfnUwVzVFAUfjXQoybtw4d99t2rRxP2sqsmYjaUBvQGNqpkyZ4sbSJEqDh7/44ovw///www/2ySefuDE+6koq6v2qOyoY51NWCCkAgBIZOXKkq5zo4Fu7dm279dZbC62klJQGuapLRmM/1M2jSoemA8+aNcuN3zj99NPdeTxUjenRo0fClRWFLIUada1oLIumIv/zn/9041hEM3YUWs477zx3/3p8haXCqiMKbTpHirqiCgspuv+gTStVqmR77rmnjR07Nqp7bM2aNVHjbIJuKw0U7t+/f9z71arEkZUPBR9dNGsomMId737jUcDRjKNnnnnGylJWKLYjMY2pBKk30Lp160pUCiwr2jGzs7NdqbKsRkqnCtoiF22Rtz00s0LjFdKpPXRA1EFJ4xASHWAZnChMB7JMX5gwFdpC3T0KOxrzEnQXaVtVuSjp2XOXL19u++yzj6uUqCpS2m2h88v89ttvNnXqVPfztdde67qu8jvBXEH7c1GOxenzDgcAwGOaLq2pyprmHEndVIl0RRVE3VL/93//5yo/pUldOuoOih2MrC9NqpiVNbp7AAAoJ7EVk6+++sr9W9gYnsLorLllQd1ZGrciCiuB4cOHW3kgpAAAkCTBgFVfVa9ePanbSHcPAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAJQDrYfTtm3b8MKIOvW+zgiry/33328+6tatW3gbg/OlTJs2zQ488MDwytFliZACAL7Tqc3jXLIqVLDKVaq4f/O7TbEunvv222+jDpqpQosc3nDDDVEnbtNp8rWCtM4WG9Cp5hUOatWq5Z6nTkdfUmvXrrXLLrvMLZSoc59oAUMtWKhT0xdE6xh99NFHUdf16tXLKleunOcstBkdUsaPH28HHHCAe9F0Ofzww93aHQAA+EqrDct7773nFu7r27dv1O+1vo5Ol1+jRo3wdVpVWUHguuuuK7Xt0OKCumhBwYULF7pVq1URKWz1Zq323KBBg7hr+Tz44INW1lImpGhdA60+OX/+fJs3b55bGlzLcS9atCjZmwYAGUvf+ps0aZKn9K/P5wsvvLBMHlOL1olW9FWlQVWHwJNPPum6VLSoXZs2beyRRx7JU4FRdaB79+4uGHTo0ME++OCD8G1WrFhhvXv3dqsa77LLLq7SoXVxAlpluVOnTla1alVr3LixW3FZi/kFtC1DhgyxoUOHWv369a1nz57u+ueee86OO+64hBaP1N/qfg877DArLe3atbPJkye756ZVlXUMvf322+3VV1+N2v5E6X50LE5kxeSMCClqkBNPPNEtnqSVHtW4Wkdg7ty5yd40AMhY/fr1s19++cVmzJgR1bWgb+nnnntuvn+ng78+w/O7aKXr/ATdD//5z39cV4lCh0yaNMlGjRrljg+LFy+2O+64w2688UZ7+umno/7++uuvt6uuusp1F+l4ogX+ggO11sDZsmWLzZ492z7//HMbO3ZseM2aH374wR2HDj30UPv0009dhV8LBt52221R96/Hq1Klir3//vv26KOPhhfq0zo4Pln3v1WIVc0pKnUX7b777u55laWUXLtHg45efPFF27Rpk+v2yY92NF0il4cWJf7yGPBTVNomLTfu47aVN9oiF22RGe0RPK/gEqm8R4nEPn5B6tSp4wKFxifo27no81lVBFUV8ruvf//737Zt27Z871fjJvL7W9130BWhA2Xglltucd0Zp512mvu5ZcuWrtr+2GOP2fnnnx++Py2Op7ARDF5VlUEL/anyohWKTz/9dHddZNVGfztu3Dhr1qyZPfTQQ64io/EdCi6qeigMVdDYIDP3ZVrhJrI9VaFR5SXyOQX/n9/zDEX8viivSSL3vWbNGreK8aBBgwq97/y2QxU0Vafi/X1w23jH26K8d1MqpCjVKpRs3rzZJdspU6bYfvvtl+/tx4wZY6NHj85z/erVq919+EYvnJKtXthgZ89UtEUu2iJve+hbb3Z2dlq1hw7YwXOLLb9XLudtKWr5/6yzzrJLL73UjVFQN4gCy5lnnlngF8I99tij2NsRXB/ZVhs3brRvvvnGLrrooqhBqPp97dq1o26rKk7w/8F4C1VktJCeKinqrnnrrbdc6FLg0XhI+eKLL6xz587h2Tmin/XYOliruqD3qbqhYrf9jz/+cINNI68Pgml+z3PH/x4n3j5REN1n8LcKU7H0hf2kk05y3WIayFvYfcdrb1HXlZ57vL/XdXp+qrLpeUfasGFDeoYUpVaV5/SB/a9//cv69+/v+gfzCyojR460YcOGRb0wSsHaKVXi8o1eUO1Q2r50+vAtDtoiF22Rtz1Unm7YsGFatYe+OOnDW8+tOOX30lTUx+/Tp49dcskl9uabb7quEA0Sve+++wq8H1UqVF3Iz5FHHhk1FiTe9kW2VVA11xgZBYdImk0TeVsdXIP/Dw6geo/pOgUcVYZU6Zk+fbrdddddrjqjmTHa33SJfF6x26L70Zfo2Oeu6o+OQZHX676Cx42n4v9mARV3n4gNB6J9TMMndAzUF/1ExsjEa2/59ddfXSUr3rbpOj2/3XbbLc9jJPKY4fuxFKI+vmDJ6I4dO9rHH39sDzzwgCvlxaNEr0usYEfzkXZYn7evPNEWuWiL9G+P4IAVXJKpqI+vrhl1kWhMiAZS6gulPqMLogBSWHdPftsRfK4HAV50sFT3g6opf/7zn+P+XXDbyDaOd50qIqoM6aIvuxqMq+m6qjxo8Gnk382ZM8dq1qzpvgDHu6+AqisaJxN5few2JLK9iVZS4t23QpIG8qr9XnnlFdfGiYi3HQrVeq0PPvjguNsW3Dbe+7Qo79uUCimxtINGjjkBACSHBsmefPLJbgxIfiEhUosWLYr9WKqi6QCrwbma+alv5qoM3HTTTXbllVe6cTKawqvjg2ag6Bt/ZFW9sJk1qqRoQK3+TgOCFU7kL3/5izvpmqoq6hJaunSpG6ir+y7swKtwEDuANz8//fSTuyxbtiw81EFBSOFJ43CkR48eritK25EIBZTjjz/eTW9+5pln3M/BOE1VaYOqjcblaKhEMK4nP5q0orBT0LjQ0pAyX0OUZjXaWv1+esH088yZMwscPQ4AKB8av6EDqA7c55xzTpk+lroSNP5FVXRVTzTdWTTl+YknnrAJEyZY+/bt7eijj3bnAwkGvyZCYzk0LkXBREFHYSWYxqxxNKoAaXaRpi6ri0vnGdG4jsLoWKUAp/YpjGYEqfIyaNAg9/NRRx3lflb1I6Aqhga/BvQ8C6q2LFiwwD788EN3/FSPhAbxBpfvvvsufDttX2EneJN//vOf7jlFnt+lLKRMJUWD5DQ6W4ObNAhKA5nU/6l55wCQ1gqY/aEBisFYiGRSJUEnCysvGiCrSyCYYaKAlN+XV832iZ2JoqpL5HWauVMQBZ/YM7BG0pfneBTgVPW499578x2iENCMI10Koi/skZYvX+62LT8FzbSKlMhtFI40LlRVqrKWMpUUzUXXi6LynQKL5scTUAAAqULnZ1E3V+SMJ1U2NNA28qRzxfHGG2+4Qb6lTV1fmg0VScdibW9RKlRpX0kBACCVqWoTeap7DcYNxu/EO/V8URRU3SkJDRrW9GnRmBjRSenK68R0hBQAAJJAXUDBQFhf7ZHA+WzKUsp09wAAgMxCSAEAjxT19OdAOu/HhBQA8EBwdlCdxwJIdVu3bnX/BudfKS7GpACAB/RhroGVmr0oOv9EYdOKfZqCnGy0hT9todlLWiNP+3BJl3ggpACAJxo1auT+DYJKYYJVZoNT6mcy2sKvttBjazZQSR+fkAIAntAHus4AqtO+F7SuTSBYZVaLuKXTOkbFQVv41RZaa680HpuQAgAedv0k0pevg5HGsmjtGg7MtEU6tkVqbz0AAEhbhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvpUxIGTNmjB166KFWs2ZNa9iwofXp08eWLl2a7M0CAACZHlJmzZplgwcPtrlz59r06dNt27Ztdvzxx9umTZuSvWkAAKAMVLIUMW3atKifJ06c6Coq8+fPt6OOOipp2wUAADK8khJr3bp17t969eole1MAAEAmV1Ii5eTk2NChQ+2II46wdu3a5Xu7LVu2uEtg/fr14b/XxTfaplAo5OW2lTfaIhdtEY32yJXz22+0xf+wX6ROWxRlu1IypGhsysKFC+29994rdLDt6NGj81y/evVq27x5s/n4wqlCpJ2rQoWULXKVCtoiF22Rtz22b99u2dnZmd0ey5dbznvv2bqTT2bf4H2SUm2xYcOG9A0pQ4YMsddee81mz55tTZs2LfC2I0eOtGHDhkVVUpo1a2YNGjSwWrVqmY87VlZWlts+H3es8kRb5KIt8rZHpUqV3Ji0jG2Pr74yO/10yxk1yrLq1GHf4H2SUm1RrVq19AspSoSXXXaZTZkyxWbOnGmtWrUq9G+qVq3qLrH0ovn4wol2LJ+3rzzRFrloi2gZ3R4rV5odd5zZTz+ZtWuX2W0Rg7ZIjbYoyjZVSqUunkmTJtnLL7/szpXyk96gZla7dm2rXr16sjcPAMrezz+bHXus2Xff7fx5//01+C7ZWwWUGf8iVj7Gjx/v+ti6detmjRs3Dl+ef/75ZG8aAJS9X381O/74nV090qyZvqUle6uAMpVS3T0AkJE2bjQ78USzzz7Lva6AmY1AukiZSgoAZCTNROzTx2zu3Ojr27dP1hYB5YaQAgC+2rbN7Oyzzd5+O+/vqKQgAxBSAMBX48ebrVplts8+eX9HJQUZgJACAL66/HKzjz4y69Vr589ZWTv/rVjRrE2bpG4aUB5SZuAsAGQkVVIee2zn/5977s4ZPer+0QmxPD3tOVBaCCkA4LOxY3eeC0UnwLrhBrMWLcweeCDZWwWUC0IKAKRCFeWcc8z23Xfn/19zTVI3CygvjEkBgFSpogSCsSlAmiOkAEAqVVGADEJIAYBUqqIAGYSQAgC+oYoCOIQUAPANVRTAIaQAgE+oogBhhBQA8AlVFCCMkAIAvqCKAkQhpACAL6iiAFEIKQDgA6ooQB6EFADwAVUUIA9CCgAkG1UUIC5CCgAkG1UUIC5CCgAkE1UUIF+EFABIJqooQL4IKQCQLFRRgAIRUgAgWaiiAAUipABAMlBFAQpFSAGAZKCKAhSKkAIA5Y0qCpAQQgoAlDeqKEBCCCkAUJ6oogAJI6QAQHmiigIkjJACAOWFKgpQJIQUACgvVFGAIiGkAEB5oIoCFBkhBQDKA1UUoMgIKQBQ1qiiAMVCSAGAskYVBSgWQgoAlCWqKECxEVIAoCxRRQGKjZACAGWFKgpQIoQUACgrVFGAEiGkAEBZoIoClBghBQDKAlUUoMQIKQBQ2qiiAKWCkAIApY0qClAqCCkAUJqoogClhpACAKWJKgpQaggpAFBaqKIApYqQAgClhSoKUKoIKQBQGqiiAKWOkAIApYEqClDqCCkAUFJUUYAyQUgBgJKiigKUCUIKAJQEVRSgzBBSAKAkqKIAZYaQAgDFRRUFKFOEFAAoLqooQJlKqZAye/Zs6927tzVp0sSysrJs6tSpyd4kAJmKKgpQ5lIqpGzatMk6dOhg48aNS/amAMh0VFGAMlfJUsgJJ5zgLgCQVFRRgHKRUpUUAPACVRSgXKRUJaWotmzZ4i6B9evXu39zcnLcxTfaplAo5OW2lTfaIhdt4Vl7/Pij2RNP7Awo555rtvfe2qjMbAuPZFpb7Nhhtnmz2datO/8NLjrk7diRY3vs4W9bFGW70jqkjBkzxkaPHp3n+tWrV9tmvZoevnDr1q1zb7QK+gDMYLRFLtoib3ts377dsrOzk9MeTz1l1q6dWVaW2eWXm2VnW7Kwb2RGW3z/vdntt+uLttm2bTuDSX7H+WbNzIYN29kWZn62xYYNGxK+bVqHlJEjR9qwYcOiKinNmjWzBg0aWK1atczHN5lmLWn7fNyxyhNtkYu2yNselSpVsoYNG5Z/e6iKcuedO7+uqopy8MGWTOwbmdEWDRuaDR1q1ru3JpDkf7vLLtsZZqpWzbHVq/1ti2rVqiV827QOKVWrVnWXWHrRfHzhRG8yn7evPNEWuWgLT9rjrrvM/vhjZ1fP9dfv/DfJ2DfSuy1+/93s9dfNXnzRbPv2+BWURo3MJk4069lz58+6jc9tUZRtSqmQsnHjRlu2bFn45+XLl9snn3xi9erVs+bNmyd12wCkOWb0IAnB5LXXdv6cn9NOM3v8cbP69S0tpVRImTdvnnXv3j38c9CV079/f5uoGAkAZYUZPUhiMNljD7N+/XaO2VaXzy67mD34oNkFF+wcHpWuUiqkdOvWzQ2KAoByRRUFSQwm/fqZHXbYzp7G++/f+f/PPGO2556W9lIqpABAUlBFQZKCSYWI4RsrVphpwup115lVypCjd4Y8TQAoJqooSGIwidS2rdlNN1lGIaQAQEGooiCJwSRSOo89yQ8hBQDyQxUFSQ4mmY6QAgD5oYqCQhBMyhYhBQDioYqCfBBMyg8hBQDioYqCCAST5CCkAEAsqiggmHiBkAIAsaiiZCyCiV8IKQAQiSpKxiGY+IuQAgCRqKJkBIJJaiCkAECAKkpaI5ikHkIKAASooqQdgklqI6QAgFBFSRsEk/RBSAEAoYqS0hRE3n9/ZzB59VWCSbogpAAAVZSUr5joX60SPH++WU7Ozt8TTFIfIQUAqKKkfFdOEEAUTPr2JZikC0IKgMxGFSUtxpiceaZZ795mRx5pVokjW9rgpQSQ2aiipMXgV8nOpnKSbggpADIXVZS0mZUTjENBeiGkAMhcVFGSjunCKAghBUBmooqSNAQTJIqQAiAzUUUpVwQTFAchBUDmoYpSLggmKClCCoDMQxWlzBBMUJoIKQAyC1WUUkcwQVkhpADILFRRSgXBBOWBkAIgc1BFKRGCCcobIQVA5qCKUmQKIm+8YfbCCwQTlD9CCoDMQBUlYQQT+IKQAiAzUEUpUTBp2tTsjDMIJihfhBQA6Y8qSlwEE/iOkAIg/VFFCSOYIJUQUgCkN6ooBBOkLEIKgPSWoVUUggnSASEFQPrKsCoKwQTphpACIH1lQBVFT2/KFIIJ0hMhBUB6SuMqSlAx0Zlff/jBbM4cs5yc3N8TTJAuCCkA0lOaVVHideXoqXXsuPP3BBOkI0IKgPSTJlWURMaYnHKK2X33mR1+OMEE6YeQAiD9pHAVpSiDXzt1MluzxqxhQwIK0hMhBUB6ScEqSnFn5USOQwHSESEFQHpJkSoK04WBwhFSAKQPz6soBBOgaAgpANKHh1UUgglQfIQUAOnBoyoKwQQoHYQUAOkhyVUUgglQ+ggpAFJfkqooBBOgbBFSAKS+cqyiEEyA8kNIAZDayqGKQjABkoOQAiC1lVEVhWACJB8hBUDqKuUqCsEE8AshBUBGV1EIJoC/CCkAUtOPPxa7ikIwAVIDIQVAarr77iJVUQgmQOohpABIPVu3mj3+eKFVFIIJkNoSfkuu0gA1D4wbN85atmxp1apVs86dO9tHH32U7E0CkIyunnyqKAoikyebnXWWWYMGO0OIQkoQUBRMhg41e/99sxUrzO67z6xLFwIK4KOE35b777+/TZo0yZLp+eeft2HDhtmoUaNswYIF1qFDB+vZs6dlZ2cndbsAlHNACd7z/6uiEEyA9JTwW/T222+3iy++2Pr162dr1661ZLj33ntt0KBBdsEFF9h+++1njz76qNWoUcP+9re/JWV7ACRpLEooZKEKFezNQ28gmABpLOG361/+8hf77LPP7JdffnEB4dVXX7XytHXrVps/f74de+yx4esqVKjgfv7ggw/KdVsAJMmqVbbj0Z1jUV7I+pP1umJfggmQxoo0cLZVq1b2zjvv2MMPP2ynn366tW3b1ipVir4LdcOUhTVr1tiOHTts9913j7pePy9ZsiTu32zZssVdAuvXr3f/5uTkuItvtE2hUMjLbStvtEUu2iLC8uX2W40mFgr9YreFRlqFCjkumPTtu/PSuXN0IEn3JmPfyEVbpE5bFGW7ijy7Z8WKFfbSSy9Z3bp17dRTT80TUnwyZswYGz16dJ7r+/bt6+V2a6favn2727asrCzLZLRFLtoi2vp9Wtnnn/1izfa6wjrXzbJddzVbtGjnJdOwb+SiLVKnLbRtiSrSkfqJJ56w4cOHuy6WRYsWWQN1BJeT+vXrW8WKFe3nn3+Oul4/N2rUKO7fjBw50g20jaykNGvWzCZPnmy1atUyH9Pl6tWrXbuqKyuT0Ra5aIto27fn2Mknn2ivv/56xrcH+0Yu2iJ12kLHYhU6SjWk9OrVy033VVfP+eefb+WtSpUq1rFjR3v77betT58+4RdCPw8ZMiTu31StWtVdYulF8/GFE6Ven7evPNEWuWiLXCqC0h65aItctEVqtEVRtinhkKLxIBo421QdwEmiqkj//v3tkEMOsU6dOtn9999vmzZtcrN9AABAekk4pEyfPt2S7ayzznIlrJtuusl++uknO/DAA23atGl5BtMCAIDU59/o0UKoaye/7h0AAJA+/OusAgAAIKQAAABfEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF5KmZBy++23W5cuXaxGjRpWp06dZG8OAAAoYykTUrZu3Wr9+vWzSy+9NNmbAgAAykElSxGjR492/06cODHZmwIAAMpByoSU4tiyZYu7BNavX+/+zcnJcRffaJtCoZCX21beaItctEU02iMXbZGLtkidtijKdqV1SBkzZky4AhNp9erVtnnzZvPxhVu3bp3buSpUSJmeuDJBW+SiLfK2x/bt2y07Ozvj24N9IxdtkTptsWHDhtQIKSNGjLCxY8cWeJvFixdbmzZtinX/I0eOtGHDhkVVUpo1a2YNGjSwWrVqmY87VlZWlts+H3es8kRb5KIt8rZHpUqVrGHDhhnfHuwbuWiL1GmLatWqpUZIGT58uA0YMKDA27Ru3brY91+1alV3iaUXzccXTrRj+bx95Ym2yEVbRKM9ctEWuWiL1GiLomxTUkOKUp4uAAAAKTsmZeXKlbZ27Vr3744dO+yTTz5x1++111626667JnvzAABApoaUm266yZ5++unwzwcddJD7d8aMGdatW7ckbhkAACgL/nVW5UPnR9FI5dgLAQUAgPSUMiEFAABkFkIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLKRFSvv32Wxs4cKC1atXKqlevbnvuuaeNGjXKtm7dmuxNAwAAZaSSpYAlS5ZYTk6OPfbYY7bXXnvZwoULbdCgQbZp0ya75557kr15AAAgU0NKr1693CXQunVrW7p0qY0fP56QAgBAmkqJkBLPunXrrF69egXeZsuWLe4SWL9+vftXVRldfKNtCoVCXm5beaMtctEW0WiPXLRFLtoiddqiKNuVkiFl2bJl9tBDDxVaRRkzZoyNHj06z/WrV6+2zZs3m48vnMKXdq4KFVJiuFCZoS1y0RZ522P79u2WnZ2d8e3BvpGLtkidttiwYUNqhJQRI0bY2LFjC7zN4sWLrU2bNuGff/jhB9f1069fPzcupSAjR460YcOGRVVSmjVrZg0aNLBatWqZjztWVlaW2z4fd6zyRFvkoi3ytkelSpWsYcOGGd8e7Bu5aIvUaYtq1aqlRkgZPny4DRgwoMDbaPxJYNWqVda9e3fr0qWLPf7444Xef9WqVd0lll40H1840Y7l8/aVJ9oiF20RjfbIRVvkoi1Soy2Ksk1JDSlKebokQhUUBZSOHTvahAkTvGx4AABQelJiTIoCSrdu3axFixZuHIrGlAQaNWqU1G0DAAAZHFKmT5/uBsvq0rRp06jfaWAQAABIPynRZ6JxKwoj8S4AACA9pURIAQAAmYeQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwUsqElFNOOcWaN29u1apVs8aNG9t5551nq1atSvZmAQCATA8p3bt3txdeeMGWLl1qkydPtq+//trOOOOMZG8WAAAoI5UsRVx55ZXh/2/RooWNGDHC+vTpY9u2bbPKlSsnddsAAEAGh5RIa9eutWeffda6dOlSYEDZsmWLuwTWr1/v/s3JyXEX32ibQqGQl9tW3miLXLRFNNojF22Ri7ZInbYoynalVEi59tpr7eGHH7bff//dDjvsMHvttdcKvP2YMWNs9OjRea5fvXq1bd682Xx84datW+d2rgoVUqYnrkzQFrloi7ztsX37dsvOzs749mDfyEVbpE5bbNiwIeHbZoX0LJJEXTZjx44t8DaLFy+2Nm3auP9fs2aNq6KsWLHChY/atWu7oJKVlZVwJaVZs2b266+/Wq1atczHHUsBqkGDBl7uWOWJtshFW+RtjxNPPNFef/31jG8P9o1ctEXqtIWOxXXr1nVBqrBjcVIrKcOHD7cBAwYUeJvWrVuH/79+/fruss8++1jbtm1d4Jg7d64dfvjhcf+2atWq7hJLL5qPL5wocPm8feWJtshFW0SjPXLRFrloi9Roi6JsU1JDilKeLiXp04qslAAAgPSREmNSPvzwQ/v444+ta9eurkSk6cc33nij7bnnnvlWUQAAQGrzrw4UR40aNeyll16yHj162L777msDBw60Aw44wGbNmhW3OwcAAKS+lKiktG/f3t55551kbwYAAChHKVFJAQAAmYeQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgJcIKQAAwEuEFAAA4CVCCgAA8BIhBQAAeImQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4qZJlkFAo5P5dv369+SgnJ8c2bNhg1apVswoVMjs/0ha5aIu87bF9+3b3Ps709mDfyEVbpE5bBMfg4JhckIwKKXrRpFmzZsneFAAlVLdu3WRvAoASHpNr165d4G2yQolEmTRKl6tWrbKaNWtaVlaW+ZguFaC+++47q1WrlmUy2iIXbRGN9shFW+SiLVKnLRQ7FFCaNGlSaKUnoyopaoymTZua77RT+bhjJQNtkYu2iEZ75KItctEWqdEWhVVQAv51VgEAABBSAACArwgpHqlataqNGjXK/ZvpaItctEU02iMXbZGLtkjPtsiogbMAACB1UEkBAABeIqQAAAAvEVIAAICXCCmeOuWUU6x58+butMaNGze28847z52ILhN9++23NnDgQGvVqpVVr17d9txzTzcobOvWrZaJbr/9duvSpYvVqFHD6tSpY5lk3Lhx1rJlS/e+6Ny5s3300UeWiWbPnm29e/d2J8PSiSmnTp1qmWrMmDF26KGHupN0NmzY0Pr06WNLly61TDR+/Hg74IADwudHOfzww+2NN96wVEZI8VT37t3thRdecG+2yZMn29dff21nnHGGZaIlS5a4swU/9thjtmjRIrvvvvvs0Ucfteuuu84ykcJZv3797NJLL7VM8vzzz9uwYcNcQF2wYIF16NDBevbsadnZ2ZZpNm3a5J6/QlummzVrlg0ePNjmzp1r06dPt23bttnxxx/v2ijTNG3a1O68806bP3++zZs3z4455hg79dRT3edmytLsHvjv5ZdfDmVlZYW2bt2a7E3xwl133RVq1apVKJNNmDAhVLt27VCm6NSpU2jw4MHhn3fs2BFq0qRJaMyYMaFMpo/xKVOmJHszvJGdne3aZNasWcneFC/UrVs39OSTT4ZSFZWUFLB27Vp79tlnXYm/cuXKyd4cL6xbt87q1auX7M1AOVaP9O3w2GOPjVrmQj9/8MEHSd02+PfZIJn++bBjxw577rnnXEVJ3T6pipDisWuvvdZ22WUX22233WzlypX28ssvJ3uTvLBs2TJ76KGH7OKLL072pqCcrFmzxn3o7r777lHX6+effvopadsFv6hbeOjQoXbEEUdYu3btLBN9/vnntuuuu7oTuV1yySU2ZcoU22+//SxVEVLK0YgRI9wgt4IuGn8RuPrqq+2///2vvfXWW1axYkU7//zz3eqRmdoe8sMPP1ivXr3cmIxBgwZZJrcFgGgam7Jw4UJXQchU++67r33yySf24YcfunFr/fv3ty+++MJSFWecLUerV6+2X375pcDbtG7d2qpUqZLn+u+//94tvT1nzpyULt2VpD00u6lbt2522GGH2cSJEwtd4jvd9w21gb41/vbbb5YJ3T2azfSvf/3Lzd4I6ANYzz+Tq4wKsPq2HNkumWjIkCFuP9DMJ80ExE7qEtWMSE08SEWVkr0BmaRBgwbuUtwypmzZssUysT1UQdGMp44dO9qECRPSKqCUdN/IBApneu3ffvvt8MFY7wn9rIMTMpe+Z1922WUuqM2cOZOAEkPvk1Q+bhBSPKQy3ccff2xdu3a1unXruunHN954o0vD6VJFKQoFFFVQWrRoYffcc4+rOgQaNWpkmUbjkzSYWv9qnIZKu7LXXnu5vuh0penHqpwccsgh1qlTJ7v//vvdoMALLrjAMs3GjRvd2KzA8uXL3X6gwaI6v1KmdfFMmjTJVVF0rpRgjFLt2rXdeZUyyciRI+2EE05w+8CGDRtcuyi4vfnmm5aykj29CHl99tlnoe7du4fq1asXqlq1aqhly5ahSy65JPT999+HMnWqrXbVeJdM1L9//7htMWPGjFC6e+ihh0LNmzcPValSxU1Jnjt3bigT6bWOtw9o38g0+X026HMj01x44YWhFi1auPdHgwYNQj169Ai99dZboVTGmBQAAOCl9OrYBwAAaYOQAgAAvERIAQAAXiKkAAAALxFSAACAlwgpAADAS4QUAADgJUIKAADwEiEFAAB4iZACwGtan6hLly52+umnR12/bt06tzL49ddfn7RtA1C2OC0+AO99+eWXduCBB9oTTzxh5557rrvu/PPPt08//dQtxqlVkgGkH0IKgJTw4IMP2s0332yLFi2yjz76yPr16+cCSocOHZK9aQDKCCEFQErQR9UxxxxjFStWtM8//9wuu+wyu+GGG5K9WQDKECEFQMpYsmSJtW3b1tq3b28LFiywSpUqJXuTAJQhBs4CSBl/+9vfrEaNGrZ8+XL7/vvvk705AMoYlRQAKWHOnDl29NFH21tvvWW33Xabu+4///mPZWVlJXvTAJQRKikAvPf777/bgAED7NJLL7Xu3bvbU0895QbPPvroo8neNABliEoKAO9dccUV9vrrr7spx+rukccee8yuuuoqN4i2ZcuWyd5EAGWAkALAa7NmzbIePXrYzJkzrWvXrlG/69mzp23fvp1uHyBNEVIAAICXGJMCAAC8REgBAABeIqQAAAAvEVIAAICXCCkAAMBLhBQAAOAlQgoAAPASIQUAAHiJkAIAALxESAEAAF4ipAAAAC8RUgAAgPno/wGtSK1D2vHC3wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "KEY INSIGHTS\n",
      "==================================================\n",
      "• Angle = 0°: Vectors point in same direction (cos = 1)\n",
      "• Angle = 90°: Vectors are perpendicular (cos = 0)\n",
      "• Angle = 180°: Vectors point in opposite directions (cos = -1)\n",
      "• Smaller angles indicate higher similarity\n",
      "• Cosine similarity is scale-invariant (doesn't depend on vector magnitude)\n",
      "• Widely used in NLP, recommendation systems, and machine learning\n"
     ]
    }
   ],
   "source": [
    "# VISUALIZATION HELPER:\n",
    "\n",
    "def plot_vectors_and_angle(u, v, title=\"Vectors and Angle\"):\n",
    "    \"\"\"Plot two 2D vectors and show the angle between them\"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    \n",
    "    # Plot vectors\n",
    "    ax.quiver(0, 0, u[0], u[1], angles='xy', scale_units='xy', scale=1, \n",
    "              color='blue', width=0.005, label=f'u = {u}')\n",
    "    ax.quiver(0, 0, v[0], v[1], angles='xy', scale_units='xy', scale=1, \n",
    "              color='red', width=0.005, label=f'v = {v}')\n",
    "    \n",
    "    # Calculate angle\n",
    "    angle = calculate_angle_between_vectors(u, v)\n",
    "    cos_sim = cosine_similarity(u, v)\n",
    "    \n",
    "    # Set equal aspect ratio and limits\n",
    "    max_val = max(torch.max(torch.abs(u)), torch.max(torch.abs(v))) * 1.2\n",
    "    ax.set_xlim(-max_val, max_val)\n",
    "    ax.set_ylim(-max_val, max_val)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Add grid and labels\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(f'{title}\\nAngle = {angle:.2f}°, Cosine similarity = {cos_sim:.4f}')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example visualization (uncomment to run)\n",
    "plot_vectors_and_angle(torch.tensor([3.0, 1.0]), torch.tensor([1.0, 2.0]))\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*50)\n",
    "print(\"• Angle = 0°: Vectors point in same direction (cos = 1)\")\n",
    "print(\"• Angle = 90°: Vectors are perpendicular (cos = 0)\")\n",
    "print(\"• Angle = 180°: Vectors point in opposite directions (cos = -1)\")\n",
    "print(\"• Smaller angles indicate higher similarity\")\n",
    "print(\"• Cosine similarity is scale-invariant (doesn't depend on vector magnitude)\")\n",
    "print(\"• Widely used in NLP, recommendation systems, and machine learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d00baaa",
   "metadata": {},
   "source": [
    "-----\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f59a61",
   "metadata": {},
   "source": [
    "## **Vector Dot Product:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fca6740",
   "metadata": {},
   "source": [
    "The vector `dot product` (also called `scalar product`) is a fundamental operation that combines two vectors to produce a scalar value. It's one of the most important operations in linear algebra with deep geometric and algebraic significance.\n",
    "\n",
    "For two vectors **$u$** = $[u₁, u₂, ..., uₙ]$ and **$v$** = $[v₁, v₂, ..., vₙ]$, the dot product is:\n",
    "\n",
    "**$u · v = u₁v₁ + u₂v₂ + ... + uₙvₙ = Σᵢ uᵢvᵢ$**\n",
    "\n",
    "**Alternatively, using the geometric definition:**\n",
    "\n",
    "**$u · v = |u| |v| cos(θ)$**\n",
    "\n",
    "where |$u$| and |$v$| are the magnitudes of the vectors, and $θ$ is the angle between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16bd37",
   "metadata": {},
   "source": [
    "#### **Mathematical Interpretation:**\n",
    "\n",
    "- Algebraically, the dot product measures how much two vectors `\"align\"` with each other. \n",
    "\n",
    "- It's a bilinear operation that satisfies the axioms of an inner product space, making it fundamental to concepts like `orthogonality`, `projection`, and `distance`. \n",
    "\n",
    "- The dot product creates a mapping from two vectors to a scalar, preserving important geometric relationships while reducing dimensionality.\n",
    "\n",
    "### **Intuitive Interpretation:**\n",
    "\n",
    "- Geometrically, the dot product represents the` \"shadow\"` or projection of one vector onto another, scaled by the length of the target vector. \n",
    "\n",
    "- Imagine shining a light perpendicular to vector **$v$** - the dot product **$u · v$** equals the length of **$u$**'s shadow on **$v$** multiplied by **$v$**'s length. \n",
    "\n",
    "- When vectors point in the same direction, their dot product is maximized; when perpendicular, it's zero; when opposite, it's minimized (negative).\n",
    "\n",
    "### **Data-Centric Interpretation:**\n",
    "\n",
    "- In data science, the dot product measures `similarity or correlation between data points` represented as vectors. \n",
    "\n",
    "- For example, in recommendation systems, the dot product of user preference vectors indicates how similar their tastes are. \n",
    "\n",
    "- In machine learning, it's used in neural networks (weighted sums), similarity metrics, and feature comparisons. \n",
    "\n",
    "- A` high positive dot product suggests similar patterns`, `zero suggests no relationship`, and `negative suggests opposite patterns`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed85ad5",
   "metadata": {},
   "source": [
    "**DOT PRODUCT BASICS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "503f9b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR DOT PRODUCT:\n",
      "============================================================\n",
      "Vectors: u = tensor([2., 3., 1.]), v = tensor([1., 2., 3.])\n",
      "Dot product (torch.dot): 11.0\n",
      "Dot product (manual): 11.0\n",
      "Dot product (@ operator): 11.0\n",
      "All methods equal: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# DOT PRODUCT BASICS:\n",
    "\n",
    "print(\"VECTOR DOT PRODUCT:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Basic dot product calculation\n",
    "u = torch.tensor([2.0, 3.0, 1.0])\n",
    "v = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# Method 1: Using torch.dot (for 1D vectors)\n",
    "dot_product = torch.dot(u, v)\n",
    "print(f\"Vectors: u = {u}, v = {v}\")\n",
    "print(f\"Dot product (torch.dot): {dot_product}\")\n",
    "\n",
    "# Method 2: Manual calculation\n",
    "manual_dot = torch.sum(u * v)\n",
    "print(f\"Dot product (manual): {manual_dot}\")\n",
    "\n",
    "# Method 3: Using matrix multiplication\n",
    "dot_matmul = u @ v\n",
    "print(f\"Dot product (@ operator): {dot_matmul}\")\n",
    "\n",
    "# Verify they're the same\n",
    "print(f\"All methods equal: {torch.allclose(dot_product, manual_dot) and torch.allclose(dot_product, dot_matmul)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7ee0d",
   "metadata": {},
   "source": [
    "**GEOMETRIC INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e80d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEOMETRIC INTERPRETATION\n",
      "============================================================\n",
      "2D Vectors: u = tensor([3., 4.]), v = tensor([1., 2.])\n",
      "Algebraic dot product: 11.0\n",
      "Geometric dot product: 11.0000\n",
      "Magnitudes: |u| = 5.0000, |v| = 2.2361\n",
      "Angle between vectors: 10.30°\n",
      "cos(θ): 0.9839\n"
     ]
    }
   ],
   "source": [
    "# GEOMETRIC INTERPRETATION:\n",
    "\n",
    "print(\"GEOMETRIC INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def geometric_dot_product(u, v):\n",
    "    \"\"\"Calculate dot product using geometric formula: |u| |v| cos(θ)\"\"\"\n",
    "    magnitude_u = torch.norm(u)\n",
    "    magnitude_v = torch.norm(v)\n",
    "    \n",
    "    # Calculate angle\n",
    "    cos_theta = torch.dot(u, v) / (magnitude_u * magnitude_v)\n",
    "    theta_rad = torch.acos(torch.clamp(cos_theta, -1, 1))\n",
    "    theta_deg = theta_rad * 180 / math.pi\n",
    "    \n",
    "    geometric_dot = magnitude_u * magnitude_v * cos_theta\n",
    "    \n",
    "    return geometric_dot, theta_deg.item(), magnitude_u.item(), magnitude_v.item()\n",
    "\n",
    "# Example with 2D vectors for visualization\n",
    "u_2d = torch.tensor([3.0, 4.0])\n",
    "v_2d = torch.tensor([1.0, 2.0])\n",
    "\n",
    "algebraic_dot = torch.dot(u_2d, v_2d)\n",
    "geometric_dot, angle, mag_u, mag_v = geometric_dot_product(u_2d, v_2d)\n",
    "\n",
    "print(f\"2D Vectors: u = {u_2d}, v = {v_2d}\")\n",
    "print(f\"Algebraic dot product: {algebraic_dot}\")\n",
    "print(f\"Geometric dot product: {geometric_dot:.4f}\")\n",
    "print(f\"Magnitudes: |u| = {mag_u:.4f}, |v| = {mag_v:.4f}\")\n",
    "print(f\"Angle between vectors: {angle:.2f}°\")\n",
    "print(f\"cos(θ): {torch.dot(u_2d, v_2d) / (torch.norm(u_2d) * torch.norm(v_2d)):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb5e1b6",
   "metadata": {},
   "source": [
    "**PROJECTION INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36835e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECTION INTERPRETATION\n",
      "============================================================\n",
      "Vectors: u = tensor([4., 2.]), v = tensor([3., 0.])\n",
      "Dot product: 12.0\n",
      "Scalar projection of u onto v: 4.0000\n",
      "Vector projection of u onto v: tensor([4., 0.])\n",
      "Dot product = |v| × scalar_projection = 3.0000 × 4.0000 = 12.0000\n"
     ]
    }
   ],
   "source": [
    "# PROJECTION INTERPRETATION:\n",
    "\n",
    "print(\"PROJECTION INTERPRETATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def vector_projection(u, v):\n",
    "    \"\"\"Calculate projection of u onto v\"\"\"\n",
    "    # Scalar projection (length of projection)\n",
    "    scalar_proj = torch.dot(u, v) / torch.norm(v)\n",
    "    \n",
    "    # Vector projection\n",
    "    vector_proj = scalar_proj * (v / torch.norm(v))\n",
    "    \n",
    "    return scalar_proj, vector_proj\n",
    "\n",
    "u_proj = torch.tensor([4.0, 2.0])\n",
    "v_proj = torch.tensor([3.0, 0.0])\n",
    "\n",
    "scalar_proj, vector_proj = vector_projection(u_proj, v_proj)\n",
    "dot_prod = torch.dot(u_proj, v_proj)\n",
    "\n",
    "print(f\"Vectors: u = {u_proj}, v = {v_proj}\")\n",
    "print(f\"Dot product: {dot_prod}\")\n",
    "print(f\"Scalar projection of u onto v: {scalar_proj:.4f}\")\n",
    "print(f\"Vector projection of u onto v: {vector_proj}\")\n",
    "print(f\"Dot product = |v| × scalar_projection = {torch.norm(v_proj):.4f} × {scalar_proj:.4f} = {torch.norm(v_proj) * scalar_proj:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167efae",
   "metadata": {},
   "source": [
    "**PROPERTIES OF DOT PRODUCT:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b2e7201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPERTIES OF DOT PRODUCT\n",
      "============================================================\n",
      "Test vectors:\n",
      "a = tensor([1., 2., 3.])\n",
      "b = tensor([4., 5., 6.])\n",
      "c = tensor([7., 8., 9.])\n",
      "scalar k = 2.5\n",
      "\n",
      "1. Commutativity: a·b = b·a\n",
      "   a·b = 32.0000\n",
      "   b·a = 32.0000\n",
      "   Equal: True\n",
      "\n",
      "2. Distributivity: a·(b + c) = a·b + a·c\n",
      "   a·(b + c) = 82.0000\n",
      "   a·b + a·c = 82.0000\n",
      "   Equal: True\n",
      "\n",
      "3. Scalar multiplication: (ka)·b = k(a·b) = a·(kb)\n",
      "   (ka)·b = 80.0000\n",
      "   k(a·b) = 80.0000\n",
      "   a·(kb) = 80.0000\n",
      "   All equal: True\n",
      "\n",
      "4. Orthogonality: a·b = 0 ⟺ a ⊥ b\n",
      "   Orthogonal vectors: tensor([1., 0.]), tensor([0., 1.])\n",
      "   Dot product: 0.0\n",
      "   Are orthogonal: True\n",
      "\n",
      "5. Self dot product: a·a = |a|²\n",
      "   a·a = 14.0000\n",
      "   |a|² = 14.0000\n",
      "   Equal: True\n",
      "\n",
      "6. Cauchy-Schwarz inequality: |a·b| ≤ |a||b|\n",
      "   |a·b| = 32.0000\n",
      "   |a||b| = 32.8329\n",
      "   Inequality satisfied: True\n"
     ]
    }
   ],
   "source": [
    "# PROPERTIES OF DOT PRODUCT: \n",
    "\n",
    "print(\"PROPERTIES OF DOT PRODUCT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test vectors\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "c = torch.tensor([7.0, 8.0, 9.0])\n",
    "k = 2.5\n",
    "\n",
    "print(\"Test vectors:\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"c = {c}\")\n",
    "print(f\"scalar k = {k}\")\n",
    "\n",
    "# Property 1: Commutativity\n",
    "print(f\"\\n1. Commutativity: a·b = b·a\")\n",
    "print(f\"   a·b = {torch.dot(a, b):.4f}\")\n",
    "print(f\"   b·a = {torch.dot(b, a):.4f}\")\n",
    "print(f\"   Equal: {torch.allclose(torch.dot(a, b), torch.dot(b, a))}\")\n",
    "\n",
    "# Property 2: Distributivity\n",
    "print(f\"\\n2. Distributivity: a·(b + c) = a·b + a·c\")\n",
    "left_side = torch.dot(a, b + c)\n",
    "right_side = torch.dot(a, b) + torch.dot(a, c)\n",
    "print(f\"   a·(b + c) = {left_side:.4f}\")\n",
    "print(f\"   a·b + a·c = {right_side:.4f}\")\n",
    "print(f\"   Equal: {torch.allclose(left_side, right_side)}\")\n",
    "\n",
    "# Property 3: Scalar multiplication\n",
    "print(f\"\\n3. Scalar multiplication: (ka)·b = k(a·b) = a·(kb)\")\n",
    "left = torch.dot(k * a, b)\n",
    "middle = k * torch.dot(a, b)\n",
    "right = torch.dot(a, k * b)\n",
    "print(f\"   (ka)·b = {left:.4f}\")\n",
    "print(f\"   k(a·b) = {middle:.4f}\")\n",
    "print(f\"   a·(kb) = {right:.4f}\")\n",
    "print(f\"   All equal: {torch.allclose(left, middle) and torch.allclose(middle, right)}\")\n",
    "\n",
    "# Property 4: Orthogonality\n",
    "print(f\"\\n4. Orthogonality: a·b = 0 ⟺ a ⊥ b\")\n",
    "ortho_a = torch.tensor([1.0, 0.0])\n",
    "ortho_b = torch.tensor([0.0, 1.0])\n",
    "print(f\"   Orthogonal vectors: {ortho_a}, {ortho_b}\")\n",
    "print(f\"   Dot product: {torch.dot(ortho_a, ortho_b)}\")\n",
    "print(f\"   Are orthogonal: {torch.abs(torch.dot(ortho_a, ortho_b)) < 1e-6}\")\n",
    "\n",
    "# Property 5: Self dot product\n",
    "print(f\"\\n5. Self dot product: a·a = |a|²\")\n",
    "self_dot = torch.dot(a, a)\n",
    "magnitude_squared = torch.norm(a) ** 2\n",
    "print(f\"   a·a = {self_dot:.4f}\")\n",
    "print(f\"   |a|² = {magnitude_squared:.4f}\")\n",
    "print(f\"   Equal: {torch.allclose(self_dot, magnitude_squared)}\")\n",
    "\n",
    "# Property 6: Cauchy-Schwarz inequality\n",
    "print(f\"\\n6. Cauchy-Schwarz inequality: |a·b| ≤ |a||b|\")\n",
    "dot_abs = torch.abs(torch.dot(a, b))\n",
    "magnitude_product = torch.norm(a) * torch.norm(b)\n",
    "print(f\"   |a·b| = {dot_abs:.4f}\")\n",
    "print(f\"   |a||b| = {magnitude_product:.4f}\")\n",
    "print(f\"   Inequality satisfied: {dot_abs <= magnitude_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d66af",
   "metadata": {},
   "source": [
    "**DATA SCIENCE APPLICATIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4f6a087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA SCIENCE APPLICATIONS\n",
      "============================================================\n",
      "1. Cosine Similarity (Normalized Dot Product)\n",
      "---------------------------------------------\n",
      "Document word frequency vectors:\n",
      "Doc1: tensor([3., 2., 1., 0., 2.])\n",
      "Doc2: tensor([2., 3., 1., 1., 1.])\n",
      "Doc3: tensor([0., 1., 0., 3., 3.])\n",
      "\n",
      "Document similarities:\n",
      "Doc1 vs Doc2: 0.8839\n",
      "Doc1 vs Doc3: 0.4326\n",
      "Doc2 vs Doc3: 0.5162\n",
      "\n",
      "2. Neural Network Weighted Sum\n",
      "-----------------------------------\n",
      "Inputs: tensor([0.5000, 0.8000, 0.2000, 0.9000])\n",
      "Weights: tensor([ 0.3000,  0.7000, -0.1000,  0.4000])\n",
      "Bias: 0.1\n",
      "Linear output: 1.1500\n",
      "\n",
      "3. Recommendation System\n",
      "-------------------------\n",
      "User preference vectors:\n",
      "Alice: tensor([5., 3., 0., 4., 2.])\n",
      "Bob: tensor([4., 4., 1., 5., 1.])\n",
      "Charlie: tensor([1., 2., 5., 1., 4.])\n",
      "\n",
      "User similarity (dot product):\n",
      "Alice vs Bob: Dot product = 54.00, Cosine similarity = 0.9567\n",
      "Alice vs Charlie: Dot product = 23.00, Cosine similarity = 0.4565\n",
      "Bob vs Charlie: Dot product = 26.00, Cosine similarity = 0.4937\n"
     ]
    }
   ],
   "source": [
    "# DATA SCIENCE APPLICATIONS: \n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA SCIENCE APPLICATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Application 1: Cosine similarity\n",
    "print(\"1. Cosine Similarity (Normalized Dot Product)\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    return torch.dot(u, v) / (torch.norm(u) * torch.norm(v))\n",
    "\n",
    "# Document vectors (word frequencies)\n",
    "doc1 = torch.tensor([3.0, 2.0, 1.0, 0.0, 2.0])  # Document 1\n",
    "doc2 = torch.tensor([2.0, 3.0, 1.0, 1.0, 1.0])  # Document 2\n",
    "doc3 = torch.tensor([0.0, 1.0, 0.0, 3.0, 3.0])  # Document 3\n",
    "\n",
    "docs = [(\"Doc1\", doc1), (\"Doc2\", doc2), (\"Doc3\", doc3)]\n",
    "\n",
    "print(\"Document word frequency vectors:\")\n",
    "for name, doc in docs:\n",
    "    print(f\"{name}: {doc}\")\n",
    "\n",
    "print(\"\\nDocument similarities:\")\n",
    "for i, (name1, doc1) in enumerate(docs):\n",
    "    for j, (name2, doc2) in enumerate(docs):\n",
    "        if i < j:\n",
    "            similarity = cosine_similarity(doc1, doc2)\n",
    "            print(f\"{name1} vs {name2}: {similarity:.4f}\")\n",
    "\n",
    "# Application 2: Weighted sum (Neural Network)\n",
    "print(f\"\\n2. Neural Network Weighted Sum\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Input features\n",
    "inputs = torch.tensor([0.5, 0.8, 0.2, 0.9])\n",
    "# Learned weights\n",
    "weights = torch.tensor([0.3, 0.7, -0.1, 0.4])\n",
    "# Bias\n",
    "bias = 0.1\n",
    "\n",
    "# Linear transformation: output = inputs·weights + bias\n",
    "linear_output = torch.dot(inputs, weights) + bias\n",
    "print(f\"Inputs: {inputs}\")\n",
    "print(f\"Weights: {weights}\")\n",
    "print(f\"Bias: {bias}\")\n",
    "print(f\"Linear output: {linear_output:.4f}\")\n",
    "\n",
    "# Application 3: Recommendation system\n",
    "print(f\"\\n3. Recommendation System\")\n",
    "print(\"-\" * 25)\n",
    "\n",
    "# User preference vectors (ratings for different items)\n",
    "user1 = torch.tensor([5.0, 3.0, 0.0, 4.0, 2.0])\n",
    "user2 = torch.tensor([4.0, 4.0, 1.0, 5.0, 1.0])\n",
    "user3 = torch.tensor([1.0, 2.0, 5.0, 1.0, 4.0])\n",
    "\n",
    "users = [(\"Alice\", user1), (\"Bob\", user2), (\"Charlie\", user3)]\n",
    "\n",
    "print(\"User preference vectors:\")\n",
    "for name, prefs in users:\n",
    "    print(f\"{name}: {prefs}\")\n",
    "\n",
    "print(\"\\nUser similarity (dot product):\")\n",
    "for i, (name1, prefs1) in enumerate(users):\n",
    "    for j, (name2, prefs2) in enumerate(users):\n",
    "        if i < j:\n",
    "            similarity = torch.dot(prefs1, prefs2)\n",
    "            cos_sim = cosine_similarity(prefs1, prefs2)\n",
    "            print(f\"{name1} vs {name2}: Dot product = {similarity:.2f}, Cosine similarity = {cos_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860aee5b",
   "metadata": {},
   "source": [
    "**BATCH OPERATIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e9e114c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BATCH OPERATIONS\n",
      "============================================================\n",
      "Method 1: Loop through vectors\n",
      "Vector 0: tensor([1., 2., 3.]) · tensor([1., 1., 1.]) = 6.0\n",
      "Vector 1: tensor([4., 5., 6.]) · tensor([1., 1., 1.]) = 15.0\n",
      "Vector 2: tensor([7., 8., 9.]) · tensor([1., 1., 1.]) = 24.0\n",
      "\n",
      "Method 2: Matrix-vector multiplication\n",
      "Batch dot products: tensor([ 6., 15., 24.])\n",
      "Using torch.mv: tensor([ 6., 15., 24.])\n",
      "All methods equal: True\n"
     ]
    }
   ],
   "source": [
    "# BATCH OPERATIONS: \n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BATCH OPERATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Batch dot products\n",
    "batch_vectors = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]\n",
    "])\n",
    "\n",
    "reference_vector = torch.tensor([1.0, 1.0, 1.0])\n",
    "\n",
    "# Method 1: Loop through vectors\n",
    "print(\"Method 1: Loop through vectors\")\n",
    "for i, vec in enumerate(batch_vectors):\n",
    "    dot_prod = torch.dot(vec, reference_vector)\n",
    "    print(f\"Vector {i}: {vec} · {reference_vector} = {dot_prod}\")\n",
    "\n",
    "# Method 2: Matrix-vector multiplication\n",
    "print(f\"\\nMethod 2: Matrix-vector multiplication\")\n",
    "batch_dots = batch_vectors @ reference_vector\n",
    "print(f\"Batch dot products: {batch_dots}\")\n",
    "\n",
    "# Method 3: Using torch.mv (matrix-vector product)\n",
    "batch_dots_mv = torch.mv(batch_vectors, reference_vector)\n",
    "print(f\"Using torch.mv: {batch_dots_mv}\")\n",
    "\n",
    "# Verify all methods give same result\n",
    "print(f\"All methods equal: {torch.allclose(batch_dots, batch_dots_mv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa457ec8",
   "metadata": {},
   "source": [
    "**SPECIAL CASES:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5266426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SPECIAL CASES\n",
      "============================================================\n",
      "1. Zero vector dot product:\n",
      "   0·a = 0.0\n",
      "\n",
      "2. Unit vectors (orthogonal):\n",
      "   e1·e2 = 0.0\n",
      "\n",
      "3. Parallel vectors:\n",
      "   Dot product: 28.0\n",
      "   Cosine similarity: 1.0000\n",
      "\n",
      "4. Anti-parallel vectors:\n",
      "   Dot product: -28.0\n",
      "   Cosine similarity: -1.0000\n"
     ]
    }
   ],
   "source": [
    "# SPECIAL CASES: \n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SPECIAL CASES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Case 1: Zero vector\n",
    "zero_vec = torch.zeros(3)\n",
    "non_zero_vec = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(f\"1. Zero vector dot product:\")\n",
    "print(f\"   0·a = {torch.dot(zero_vec, non_zero_vec)}\")\n",
    "\n",
    "# Case 2: Unit vectors\n",
    "unit_vec1 = torch.tensor([1.0, 0.0, 0.0])\n",
    "unit_vec2 = torch.tensor([0.0, 1.0, 0.0])\n",
    "print(f\"\\n2. Unit vectors (orthogonal):\")\n",
    "print(f\"   e1·e2 = {torch.dot(unit_vec1, unit_vec2)}\")\n",
    "\n",
    "# Case 3: Parallel vectors\n",
    "parallel_vec1 = torch.tensor([2.0, 4.0, 6.0])\n",
    "parallel_vec2 = torch.tensor([1.0, 2.0, 3.0])\n",
    "print(f\"\\n3. Parallel vectors:\")\n",
    "print(f\"   Dot product: {torch.dot(parallel_vec1, parallel_vec2)}\")\n",
    "print(f\"   Cosine similarity: {cosine_similarity(parallel_vec1, parallel_vec2):.4f}\")\n",
    "\n",
    "# Case 4: Anti-parallel vectors\n",
    "anti_parallel_vec1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "anti_parallel_vec2 = torch.tensor([-2.0, -4.0, -6.0])\n",
    "print(f\"\\n4. Anti-parallel vectors:\")\n",
    "print(f\"   Dot product: {torch.dot(anti_parallel_vec1, anti_parallel_vec2)}\")\n",
    "print(f\"   Cosine similarity: {cosine_similarity(anti_parallel_vec1, anti_parallel_vec2):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08a259ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPUTATIONAL COMPLEXITY\n",
      "============================================================\n",
      "Dot product computational complexity:\n",
      "• Time complexity: O(n) where n is vector dimension\n",
      "• Space complexity: O(1) - only stores the scalar result\n",
      "• Highly optimized in modern libraries (BLAS, SIMD)\n",
      "• Parallelizable for batch operations\n",
      "\n",
      "Timing example (1M dimensions):\n",
      "Time taken: 4.13 ms\n",
      "Result: 1412.1254\n"
     ]
    }
   ],
   "source": [
    "# COMPUTATIONAL COMPLEXITY: \n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPUTATIONAL COMPLEXITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Dot product computational complexity:\")\n",
    "print(\"• Time complexity: O(n) where n is vector dimension\")\n",
    "print(\"• Space complexity: O(1) - only stores the scalar result\")\n",
    "print(\"• Highly optimized in modern libraries (BLAS, SIMD)\")\n",
    "print(\"• Parallelizable for batch operations\")\n",
    "\n",
    "# Timing example\n",
    "import time\n",
    "\n",
    "large_vec1 = torch.randn(1000000)\n",
    "large_vec2 = torch.randn(1000000)\n",
    "\n",
    "start_time = time.time()\n",
    "result = torch.dot(large_vec1, large_vec2)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nTiming example (1M dimensions):\")\n",
    "print(f\"Time taken: {(end_time - start_time) * 1000:.2f} ms\")\n",
    "print(f\"Result: {result:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36dabd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "KEY TAKEAWAYS\n",
      "============================================================\n",
      "Mathematical Properties:\n",
      "• Commutative: a·b = b·a\n",
      "• Distributive: a·(b+c) = a·b + a·c\n",
      "• Linear in each argument\n",
      "• Self dot product gives squared magnitude\n",
      "\n",
      "Geometric Interpretation:\n",
      "• Measures alignment between vectors\n",
      "• Positive: same general direction\n",
      "• Zero: orthogonal vectors\n",
      "• Negative: opposite general direction\n",
      "\n",
      "Data Science Applications:\n",
      "• Similarity measurement (cosine similarity)\n",
      "• Neural network linear transformations\n",
      "• Recommendation systems\n",
      "• Principal component analysis\n",
      "• Feature correlation analysis\n",
      "\n",
      "Computational Aspects:\n",
      "• O(n) time complexity\n",
      "• Highly optimized in modern libraries\n",
      "• Foundation for matrix operations\n",
      "• Essential for deep learning frameworks\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"KEY TAKEAWAYS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"Mathematical Properties:\")\n",
    "print(\"• Commutative: a·b = b·a\")\n",
    "print(\"• Distributive: a·(b+c) = a·b + a·c\")\n",
    "print(\"• Linear in each argument\")\n",
    "print(\"• Self dot product gives squared magnitude\")\n",
    "\n",
    "print(\"\\nGeometric Interpretation:\")\n",
    "print(\"• Measures alignment between vectors\")\n",
    "print(\"• Positive: same general direction\")\n",
    "print(\"• Zero: orthogonal vectors\")\n",
    "print(\"• Negative: opposite general direction\")\n",
    "\n",
    "print(\"\\nData Science Applications:\")\n",
    "print(\"• Similarity measurement (cosine similarity)\")\n",
    "print(\"• Neural network linear transformations\")\n",
    "print(\"• Recommendation systems\")\n",
    "print(\"• Principal component analysis\")\n",
    "print(\"• Feature correlation analysis\")\n",
    "\n",
    "print(\"\\nComputational Aspects:\")\n",
    "print(\"• O(n) time complexity\")\n",
    "print(\"• Highly optimized in modern libraries\")\n",
    "print(\"• Foundation for matrix operations\")\n",
    "print(\"• Essential for deep learning frameworks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa1f1c1",
   "metadata": {},
   "source": [
    "#### **Properties of Vector Dot Product:** \n",
    "\n",
    "The dot product has several fundamental properties that make it mathematically elegant and computationally useful:\n",
    "\n",
    "**1. Commutativity**: $a · b = b · a$  \n",
    "\n",
    "**2. Distributivity**: $a · (b + c) = a · b + a · c$\n",
    "\n",
    "**3. Scalar Multiplication**: $(ka) · b = k(a · b) = a · (kb)$\n",
    "\n",
    "**4. Orthogonality**: $a · b = 0$ if and only if $a ⊥ b$\n",
    "\n",
    "**5. Self Dot Product**: $a · a = |a|²$ (squared magnitude)\n",
    "\n",
    "**6. Cauchy-Schwarz Inequality**: $|a · b| ≤ |a| |b|$\n",
    "\n",
    "**7. Linearity**: The dot product is linear in each argument\n",
    "\n",
    "**8. Positive Definiteness**: $a · a ≥ 0$, with equality only when $a = 0$\n",
    "\n",
    "These properties make the dot product a true inner product, which is fundamental to many areas of mathematics and its applications. The dot product serves as the foundation for concepts like `orthogonal projections`, `least squares optimization`, `principal component analysis`, and `neural network computations`. \n",
    "\n",
    "Its computational efficiency ($O(n)$ time complexity) and the fact that it reduces two vectors to a single scalar make it indispensable in high-dimensional data analysis and machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3203e5",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c6c3d",
   "metadata": {},
   "source": [
    "## **Cross Product:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262dde87",
   "metadata": {},
   "source": [
    "The `cross product` (also called `vector product`) is a binary operation on two vectors in 3D space that produces a third vector perpendicular to both input vectors. Unlike the dot product which yields a scalar, the cross product yields a vector, making it fundamentally different in nature and application.\n",
    "\n",
    "For two 3D vectors **$a$** = $[a₁, a₂, a₃]$ and **$b$** = $[b₁, b₂, b₃]$, the cross product **`a × b`** is:\n",
    "\n",
    "> **$a × b = [a₂b₃ - a₃b₂, a₃b₁ - a₁b₃, a₁b₂ - a₂b₁]$**\n",
    "\n",
    "Alternatively, using the determinant formula:\n",
    "\n",
    "```raw\n",
    "a × b =  | i  j  k|  \n",
    "         |a₁ a₂ a₃|  \n",
    "         |b₁ b₂ b₃|  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7fb1de",
   "metadata": {},
   "source": [
    "The magnitude is: **$|a × b| = |a| |b| sin(θ)$** where $θ$ is the angle between vectors.\n",
    "\n",
    "**Key Differences from Dot Product**\n",
    "\n",
    "| Aspect | Dot Product | Cross Product |\n",
    "|--------|-------------|---------------|\n",
    "| **Result** | Scalar | Vector |\n",
    "| **Dimensionality** | Works in any dimension | Only defined in 3D (and 7D) |\n",
    "| **Geometric meaning** | Measures alignment | Measures perpendicularity |\n",
    "| **Magnitude formula** | \\|a\\| \\|b\\| cos(θ) | \\|a\\| \\|b\\| sin(θ) |\n",
    "| **Commutativity** | a · b = b · a | a × b = -(b × a) |\n",
    "| **Parallel vectors** | Maximum value | Zero |\n",
    "| **Perpendicular vectors** | Zero | Maximum value |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7927d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d393287",
   "metadata": {},
   "source": [
    "**CROSS PRODUCT BASICS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46b715be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR CROSS PRODUCT - COMPREHENSIVE GUIDE\n",
      "======================================================================\n",
      "Vectors: a = tensor([1., 2., 3.]), b = tensor([4., 5., 6.])\n",
      "Cross product (manual): tensor([-3.,  6., -3.])\n",
      "Magnitude: 7.3485\n",
      "Cross product (torch.cross): tensor([-3.,  6., -3.])\n",
      "Results match: True\n",
      "(a × b) · a = 0.000000 (should be ~0)\n",
      "(a × b) · b = 0.000000 (should be ~0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MyMachine\\AppData\\Local\\Temp\\ipykernel_11460\\162448904.py:32: UserWarning: Using torch.cross without specifying the dim arg is deprecated.\n",
      "Please either pass the dim explicitly or simply use torch.linalg.cross.\n",
      "The default value of dim will change to agree with that of linalg.cross in a future release. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\Cross.cpp:66.)\n",
      "  cross_torch = torch.cross(a, b)\n"
     ]
    }
   ],
   "source": [
    "# CROSS PRODUCT BASICS\n",
    "\n",
    "print(\"VECTOR CROSS PRODUCT - COMPREHENSIVE GUIDE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def cross_product_3d(a, b):\n",
    "    \"\"\"\n",
    "    Calculate cross product of two 3D vectors\n",
    "    Returns the cross product vector and its magnitude\n",
    "    \"\"\"\n",
    "    # Manual calculation using the formula\n",
    "    cross = torch.tensor([\n",
    "        a[1]*b[2] - a[2]*b[1],  # i component\n",
    "        a[2]*b[0] - a[0]*b[2],  # j component\n",
    "        a[0]*b[1] - a[1]*b[0]   # k component\n",
    "    ])\n",
    "    \n",
    "    magnitude = torch.norm(cross)\n",
    "    return cross, magnitude\n",
    "\n",
    "# Example vectors\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# Method 1: Manual calculation\n",
    "cross_manual, mag_manual = cross_product_3d(a, b)\n",
    "print(f\"Vectors: a = {a}, b = {b}\")\n",
    "print(f\"Cross product (manual): {cross_manual}\")\n",
    "print(f\"Magnitude: {mag_manual:.4f}\")\n",
    "\n",
    "# Method 2: Using torch.cross\n",
    "cross_torch = torch.cross(a, b)\n",
    "print(f\"Cross product (torch.cross): {cross_torch}\")\n",
    "print(f\"Results match: {torch.allclose(cross_manual, cross_torch)}\")\n",
    "\n",
    "# Verify perpendicularity\n",
    "dot_with_a = torch.dot(cross_torch, a)\n",
    "dot_with_b = torch.dot(cross_torch, b)\n",
    "print(f\"(a × b) · a = {dot_with_a:.6f} (should be ~0)\")\n",
    "print(f\"(a × b) · b = {dot_with_b:.6f} (should be ~0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d584cfe",
   "metadata": {},
   "source": [
    "**GEOMETRIC INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e17a7b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GEOMETRIC INTERPRETATION\n",
      "======================================================================\n",
      "\n",
      "Unit vectors (90°):\n",
      "a = tensor([1., 0., 0.]), b = tensor([0., 1., 0.])\n",
      "Cross product: tensor([0., 0., 1.])\n",
      "Magnitude: 1.0000\n",
      "Angle: 90.00°\n",
      "sin(θ): 1.0000\n",
      "Geometric formula verified: True\n",
      "\n",
      "45° vectors:\n",
      "a = tensor([1., 1., 0.]), b = tensor([ 1., -1.,  0.])\n",
      "Cross product: tensor([ 0.,  0., -2.])\n",
      "Magnitude: 2.0000\n",
      "Angle: 90.00°\n",
      "sin(θ): 1.0000\n",
      "Geometric formula verified: True\n",
      "\n",
      "Parallel vectors:\n",
      "a = tensor([2., 0., 0.]), b = tensor([4., 0., 0.])\n",
      "Cross product: tensor([0., 0., 0.])\n",
      "Magnitude: 0.0000\n",
      "Angle: 0.00°\n",
      "sin(θ): 0.0000\n",
      "Geometric formula verified: True\n",
      "\n",
      "Parallel vectors (scaled):\n",
      "a = tensor([1., 2., 3.]), b = tensor([2., 4., 6.])\n",
      "Cross product: tensor([0., 0., 0.])\n",
      "Magnitude: 0.0000\n",
      "Angle: 0.02°\n",
      "sin(θ): 0.0003\n",
      "Geometric formula verified: False\n"
     ]
    }
   ],
   "source": [
    "# GEOMETRIC INTERPRETATION \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GEOMETRIC INTERPRETATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def geometric_cross_product_analysis(a, b):\n",
    "    \"\"\"Analyze cross product from geometric perspective\"\"\"\n",
    "    # Calculate cross product\n",
    "    cross = torch.cross(a, b)\n",
    "    \n",
    "    # Calculate magnitudes\n",
    "    mag_a = torch.norm(a)\n",
    "    mag_b = torch.norm(b)\n",
    "    mag_cross = torch.norm(cross)\n",
    "    \n",
    "    # Calculate angle between original vectors\n",
    "    cos_theta = torch.dot(a, b) / (mag_a * mag_b)\n",
    "    cos_theta = torch.clamp(cos_theta, -1, 1)\n",
    "    theta_rad = torch.acos(cos_theta)\n",
    "    theta_deg = theta_rad * 180 / math.pi\n",
    "    \n",
    "    # Verify geometric formula: |a × b| = |a| |b| sin(θ)\n",
    "    sin_theta = torch.sin(theta_rad)\n",
    "    geometric_magnitude = mag_a * mag_b * sin_theta\n",
    "    \n",
    "    return {\n",
    "        'cross_product': cross,\n",
    "        'magnitude': mag_cross,\n",
    "        'angle_degrees': theta_deg.item(),\n",
    "        'sin_theta': sin_theta.item(),\n",
    "        'geometric_magnitude': geometric_magnitude.item(),\n",
    "        'formula_verified': torch.allclose(mag_cross, geometric_magnitude)\n",
    "    }\n",
    "\n",
    "# Test with different vector pairs\n",
    "test_cases = [\n",
    "    (torch.tensor([1.0, 0.0, 0.0]), torch.tensor([0.0, 1.0, 0.0]), \"Unit vectors (90°)\"),\n",
    "    (torch.tensor([1.0, 1.0, 0.0]), torch.tensor([1.0, -1.0, 0.0]), \"45° vectors\"),\n",
    "    (torch.tensor([2.0, 0.0, 0.0]), torch.tensor([4.0, 0.0, 0.0]), \"Parallel vectors\"),\n",
    "    (torch.tensor([1.0, 2.0, 3.0]), torch.tensor([2.0, 4.0, 6.0]), \"Parallel vectors (scaled)\"),\n",
    "]\n",
    "\n",
    "for a, b, description in test_cases:\n",
    "    print(f\"\\n{description}:\")\n",
    "    print(f\"a = {a}, b = {b}\")\n",
    "    \n",
    "    result = geometric_cross_product_analysis(a, b)\n",
    "    print(f\"Cross product: {result['cross_product']}\")\n",
    "    print(f\"Magnitude: {result['magnitude']:.4f}\")\n",
    "    print(f\"Angle: {result['angle_degrees']:.2f}°\")\n",
    "    print(f\"sin(θ): {result['sin_theta']:.4f}\")\n",
    "    print(f\"Geometric formula verified: {result['formula_verified']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ef0f8",
   "metadata": {},
   "source": [
    "**PROPERTIES OF CROSS PRODUCT:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13fccba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROPERTIES OF CROSS PRODUCT\n",
      "======================================================================\n",
      "Test vectors:\n",
      "a = tensor([1., 2., 3.])\n",
      "b = tensor([4., 5., 6.])\n",
      "c = tensor([7., 8., 9.])\n",
      "scalar k = 2.5\n",
      "\n",
      "1. Anti-commutativity: a × b = -(b × a)\n",
      "   a × b = tensor([-3.,  6., -3.])\n",
      "   b × a = tensor([ 3., -6.,  3.])\n",
      "   a × b = -(b × a): True\n",
      "\n",
      "2. Distributivity: a × (b + c) = a × b + a × c\n",
      "   a × (b + c) = tensor([-9., 18., -9.])\n",
      "   a × b + a × c = tensor([-9., 18., -9.])\n",
      "   Equal: True\n",
      "\n",
      "3. Scalar multiplication: (ka) × b = k(a × b) = a × (kb)\n",
      "   (ka) × b = tensor([-7.5000, 15.0000, -7.5000])\n",
      "   k(a × b) = tensor([-7.5000, 15.0000, -7.5000])\n",
      "   a × (kb) = tensor([-7.5000, 15.0000, -7.5000])\n",
      "   All equal: True\n",
      "\n",
      "4. Self cross product: a × a = 0\n",
      "   a × a = tensor([0., 0., 0.])\n",
      "   Is zero: True\n",
      "\n",
      "5. Orthogonality: (a × b) ⊥ a and (a × b) ⊥ b\n",
      "   (a × b) · a = 0.000000\n",
      "   (a × b) · b = 0.000000\n",
      "   Both orthogonal: True\n",
      "\n",
      "6. Parallel vectors: If a ∥ b, then a × b = 0\n",
      "   Parallel vectors: tensor([1., 2., 3.]), tensor([2., 4., 6.])\n",
      "   Cross product: tensor([0., 0., 0.])\n",
      "   Is zero: True\n"
     ]
    }
   ],
   "source": [
    "# PROPERTIES OF CROSS PRODUCT: \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROPERTIES OF CROSS PRODUCT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test vectors\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "c = torch.tensor([7.0, 8.0, 9.0])\n",
    "k = 2.5\n",
    "\n",
    "print(\"Test vectors:\")\n",
    "print(f\"a = {a}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"c = {c}\")\n",
    "print(f\"scalar k = {k}\")\n",
    "\n",
    "# Property 1: Anti-commutativity\n",
    "print(f\"\\n1. Anti-commutativity: a × b = -(b × a)\")\n",
    "cross_ab = torch.cross(a, b)\n",
    "cross_ba = torch.cross(b, a)\n",
    "print(f\"   a × b = {cross_ab}\")\n",
    "print(f\"   b × a = {cross_ba}\")\n",
    "print(f\"   a × b = -(b × a): {torch.allclose(cross_ab, -cross_ba)}\")\n",
    "\n",
    "# Property 2: Distributivity\n",
    "print(f\"\\n2. Distributivity: a × (b + c) = a × b + a × c\")\n",
    "left_side = torch.cross(a, b + c)\n",
    "right_side = torch.cross(a, b) + torch.cross(a, c)\n",
    "print(f\"   a × (b + c) = {left_side}\")\n",
    "print(f\"   a × b + a × c = {right_side}\")\n",
    "print(f\"   Equal: {torch.allclose(left_side, right_side)}\")\n",
    "\n",
    "# Property 3: Scalar multiplication\n",
    "print(f\"\\n3. Scalar multiplication: (ka) × b = k(a × b) = a × (kb)\")\n",
    "left = torch.cross(k * a, b)\n",
    "middle = k * torch.cross(a, b)\n",
    "right = torch.cross(a, k * b)\n",
    "print(f\"   (ka) × b = {left}\")\n",
    "print(f\"   k(a × b) = {middle}\")\n",
    "print(f\"   a × (kb) = {right}\")\n",
    "print(f\"   All equal: {torch.allclose(left, middle) and torch.allclose(middle, right)}\")\n",
    "\n",
    "# Property 4: Self cross product\n",
    "print(f\"\\n4. Self cross product: a × a = 0\")\n",
    "self_cross = torch.cross(a, a)\n",
    "print(f\"   a × a = {self_cross}\")\n",
    "print(f\"   Is zero: {torch.allclose(self_cross, torch.zeros(3))}\")\n",
    "\n",
    "# Property 5: Orthogonality\n",
    "print(f\"\\n5. Orthogonality: (a × b) ⊥ a and (a × b) ⊥ b\")\n",
    "cross_ab = torch.cross(a, b)\n",
    "dot_cross_a = torch.dot(cross_ab, a)\n",
    "dot_cross_b = torch.dot(cross_ab, b)\n",
    "print(f\"   (a × b) · a = {dot_cross_a:.6f}\")\n",
    "print(f\"   (a × b) · b = {dot_cross_b:.6f}\")\n",
    "print(f\"   Both orthogonal: {abs(dot_cross_a) < 1e-5 and abs(dot_cross_b) < 1e-5}\")\n",
    "\n",
    "# Property 6: Parallel vectors\n",
    "print(f\"\\n6. Parallel vectors: If a ∥ b, then a × b = 0\")\n",
    "parallel_a = torch.tensor([1.0, 2.0, 3.0])\n",
    "parallel_b = torch.tensor([2.0, 4.0, 6.0])\n",
    "cross_parallel = torch.cross(parallel_a, parallel_b)\n",
    "print(f\"   Parallel vectors: {parallel_a}, {parallel_b}\")\n",
    "print(f\"   Cross product: {cross_parallel}\")\n",
    "print(f\"   Is zero: {torch.allclose(cross_parallel, torch.zeros(3))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec60cb4",
   "metadata": {},
   "source": [
    "**COMPARISON WITH DOT PRODUCT:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4014eb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CROSS PRODUCT VS DOT PRODUCT COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Perpendicular: a = tensor([1., 0., 0.]), b = tensor([0., 1., 0.])\n",
      "  Dot product: 0.0000\n",
      "  Cross product: tensor([0., 0., 1.])\n",
      "  Cross magnitude: 1.0000\n",
      "  Angle: 90.00°\n",
      "  cos(θ): 0.0000, sin(θ): 1.0000\n",
      "\n",
      "Parallel (same): a = tensor([1., 0., 0.]), b = tensor([1., 0., 0.])\n",
      "  Dot product: 1.0000\n",
      "  Cross product: tensor([0., 0., 0.])\n",
      "  Cross magnitude: 0.0000\n",
      "  Angle: 0.00°\n",
      "  cos(θ): 1.0000, sin(θ): 0.0000\n",
      "\n",
      "Parallel (opposite): a = tensor([1., 0., 0.]), b = tensor([-1.,  0.,  0.])\n",
      "  Dot product: -1.0000\n",
      "  Cross product: tensor([0., -0., 0.])\n",
      "  Cross magnitude: 0.0000\n",
      "  Angle: 180.00°\n",
      "  cos(θ): -1.0000, sin(θ): -0.0000\n",
      "\n",
      "45° angle: a = tensor([1., 1., 0.]), b = tensor([ 1., -1.,  0.])\n",
      "  Dot product: 0.0000\n",
      "  Cross product: tensor([ 0.,  0., -2.])\n",
      "  Cross magnitude: 2.0000\n",
      "  Angle: 90.00°\n",
      "  cos(θ): 0.0000, sin(θ): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# COMPARISON WITH DOT PRODUCT: \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS PRODUCT VS DOT PRODUCT COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def compare_products(a, b):\n",
    "    \"\"\"Compare dot and cross products for given vectors\"\"\"\n",
    "    # Dot product\n",
    "    dot_prod = torch.dot(a, b)\n",
    "    \n",
    "    # Cross product\n",
    "    cross_prod = torch.cross(a, b)\n",
    "    cross_magnitude = torch.norm(cross_prod)\n",
    "    \n",
    "    # Angle\n",
    "    cos_theta = dot_prod / (torch.norm(a) * torch.norm(b))\n",
    "    cos_theta = torch.clamp(cos_theta, -1, 1)\n",
    "    theta_rad = torch.acos(cos_theta)\n",
    "    theta_deg = theta_rad * 180 / math.pi\n",
    "    \n",
    "    return {\n",
    "        'dot_product': dot_prod.item(),\n",
    "        'cross_product': cross_prod,\n",
    "        'cross_magnitude': cross_magnitude.item(),\n",
    "        'angle_degrees': theta_deg.item(),\n",
    "        'cos_theta': cos_theta.item(),\n",
    "        'sin_theta': torch.sin(theta_rad).item()\n",
    "    }\n",
    "\n",
    "comparison_cases = [\n",
    "    (torch.tensor([1.0, 0.0, 0.0]), torch.tensor([0.0, 1.0, 0.0]), \"Perpendicular\"),\n",
    "    (torch.tensor([1.0, 0.0, 0.0]), torch.tensor([1.0, 0.0, 0.0]), \"Parallel (same)\"),\n",
    "    (torch.tensor([1.0, 0.0, 0.0]), torch.tensor([-1.0, 0.0, 0.0]), \"Parallel (opposite)\"),\n",
    "    (torch.tensor([1.0, 1.0, 0.0]), torch.tensor([1.0, -1.0, 0.0]), \"45° angle\"),\n",
    "]\n",
    "\n",
    "for a, b, description in comparison_cases:\n",
    "    print(f\"\\n{description}: a = {a}, b = {b}\")\n",
    "    result = compare_products(a, b)\n",
    "    print(f\"  Dot product: {result['dot_product']:.4f}\")\n",
    "    print(f\"  Cross product: {result['cross_product']}\")\n",
    "    print(f\"  Cross magnitude: {result['cross_magnitude']:.4f}\")\n",
    "    print(f\"  Angle: {result['angle_degrees']:.2f}°\")\n",
    "    print(f\"  cos(θ): {result['cos_theta']:.4f}, sin(θ): {result['sin_theta']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300c8725",
   "metadata": {},
   "source": [
    "**APPLICATIONS IN MACHINE LEARNING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34e10f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MACHINE LEARNING APPLICATIONS\n",
      "======================================================================\n",
      "1. Surface Normal Calculation (Computer Vision)\n",
      "--------------------------------------------------\n",
      "Triangle vertices: tensor([0., 0., 0.]), tensor([1., 0., 0.]), tensor([0., 1., 0.])\n",
      "Surface normal: tensor([0., 0., 1.])\n",
      "Unit normal: tensor([0., 0., 1.])\n",
      "\n",
      "2. Rotation Axis Calculation\n",
      "------------------------------\n",
      "From vector: tensor([1., 0., 0.])\n",
      "To vector: tensor([0., 1., 0.])\n",
      "Rotation axis: tensor([0., 0., 1.])\n",
      "Rotation angle: 90.00°\n",
      "\n",
      "3. Parallelogram/Triangle Area\n",
      "-----------------------------------\n",
      "Parallelogram sides: tensor([3., 0., 0.]), tensor([1., 2., 0.])\n",
      "Parallelogram area: 6.0000\n",
      "Triangle area: 3.0000\n",
      "\n",
      "4. Physics Simulation (Torque)\n",
      "-----------------------------------\n",
      "Position: tensor([2., 0., 0.])\n",
      "Force: tensor([ 0., 10.,  0.])\n",
      "Torque: tensor([ 0.,  0., 20.])\n",
      "Torque magnitude: 20.0000\n"
     ]
    }
   ],
   "source": [
    "# APPLICATIONS IN MACHINE LEARNING: \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MACHINE LEARNING APPLICATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Application 1: Surface Normal Calculation\n",
    "print(\"1. Surface Normal Calculation (Computer Vision)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def calculate_surface_normal(p1, p2, p3):\n",
    "    \"\"\"Calculate normal vector to a triangle surface\"\"\"\n",
    "    # Create two edge vectors\n",
    "    edge1 = p2 - p1\n",
    "    edge2 = p3 - p1\n",
    "    \n",
    "    # Normal is cross product of edges\n",
    "    normal = torch.cross(edge1, edge2)\n",
    "    \n",
    "    # Normalize\n",
    "    normal_unit = normal / torch.norm(normal)\n",
    "    \n",
    "    return normal, normal_unit\n",
    "\n",
    "# Triangle vertices\n",
    "vertex1 = torch.tensor([0.0, 0.0, 0.0])\n",
    "vertex2 = torch.tensor([1.0, 0.0, 0.0])\n",
    "vertex3 = torch.tensor([0.0, 1.0, 0.0])\n",
    "\n",
    "normal, normal_unit = calculate_surface_normal(vertex1, vertex2, vertex3)\n",
    "print(f\"Triangle vertices: {vertex1}, {vertex2}, {vertex3}\")\n",
    "print(f\"Surface normal: {normal}\")\n",
    "print(f\"Unit normal: {normal_unit}\")\n",
    "\n",
    "# Application 2: Rotation and Orientation\n",
    "print(f\"\\n2. Rotation Axis Calculation\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "def find_rotation_axis(from_vec, to_vec):\n",
    "    \"\"\"Find axis of rotation to transform from_vec to to_vec\"\"\"\n",
    "    # Normalize vectors\n",
    "    from_norm = from_vec / torch.norm(from_vec)\n",
    "    to_norm = to_vec / torch.norm(to_vec)\n",
    "    \n",
    "    # Rotation axis is cross product\n",
    "    rotation_axis = torch.cross(from_norm, to_norm)\n",
    "    \n",
    "    if torch.norm(rotation_axis) < 1e-6:\n",
    "        return None, 0.0  # Parallel vectors\n",
    "    \n",
    "    rotation_axis_unit = rotation_axis / torch.norm(rotation_axis)\n",
    "    \n",
    "    # Rotation angle\n",
    "    cos_angle = torch.dot(from_norm, to_norm)\n",
    "    angle_rad = torch.acos(torch.clamp(cos_angle, -1, 1))\n",
    "    angle_deg = angle_rad * 180 / math.pi\n",
    "    \n",
    "    return rotation_axis_unit, angle_deg.item()\n",
    "\n",
    "from_vector = torch.tensor([1.0, 0.0, 0.0])\n",
    "to_vector = torch.tensor([0.0, 1.0, 0.0])\n",
    "\n",
    "axis, angle = find_rotation_axis(from_vector, to_vector)\n",
    "print(f\"From vector: {from_vector}\")\n",
    "print(f\"To vector: {to_vector}\")\n",
    "print(f\"Rotation axis: {axis}\")\n",
    "print(f\"Rotation angle: {angle:.2f}°\")\n",
    "\n",
    "# Application 3: Area Calculation\n",
    "print(f\"\\n3. Parallelogram/Triangle Area\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "def calculate_parallelogram_area(a, b):\n",
    "    \"\"\"Calculate area of parallelogram formed by vectors a and b\"\"\"\n",
    "    cross_prod = torch.cross(a, b)\n",
    "    area = torch.norm(cross_prod)\n",
    "    return area\n",
    "\n",
    "# Parallelogram defined by two vectors\n",
    "side1 = torch.tensor([3.0, 0.0, 0.0])\n",
    "side2 = torch.tensor([1.0, 2.0, 0.0])\n",
    "\n",
    "area = calculate_parallelogram_area(side1, side2)\n",
    "triangle_area = area / 2\n",
    "\n",
    "print(f\"Parallelogram sides: {side1}, {side2}\")\n",
    "print(f\"Parallelogram area: {area:.4f}\")\n",
    "print(f\"Triangle area: {triangle_area:.4f}\")\n",
    "\n",
    "# Application 4: Physics Simulation (Torque)\n",
    "print(f\"\\n4. Physics Simulation (Torque)\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "def calculate_torque(position, force):\n",
    "    \"\"\"Calculate torque: τ = r × F\"\"\"\n",
    "    torque = torch.cross(position, force)\n",
    "    torque_magnitude = torch.norm(torque)\n",
    "    return torque, torque_magnitude\n",
    "\n",
    "# Example: force applied at a position\n",
    "position = torch.tensor([2.0, 0.0, 0.0])  # Position vector\n",
    "force = torch.tensor([0.0, 10.0, 0.0])    # Force vector\n",
    "\n",
    "torque, torque_mag = calculate_torque(position, force)\n",
    "print(f\"Position: {position}\")\n",
    "print(f\"Force: {force}\")\n",
    "print(f\"Torque: {torque}\")\n",
    "print(f\"Torque magnitude: {torque_mag:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f420100b",
   "metadata": {},
   "source": [
    "**DEEP LEARNING APPLICATIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46ce1c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DEEP LEARNING APPLICATIONS\n",
      "======================================================================\n",
      "1. 3D CNN Spatial Feature Relationships\n",
      "---------------------------------------------\n",
      "3D spatial perpendicular directions:\n",
      "  perpendicular_xy: tensor([0., 0., 1.])\n",
      "  perpendicular_xz: tensor([ 0., -1.,  0.])\n",
      "  perpendicular_yz: tensor([1., 0., 0.])\n",
      "\n",
      "2. Attention Mechanism with Geometric Relationships\n",
      "-------------------------------------------------------\n",
      "Query: tensor([1., 2., 3.])\n",
      "Key: tensor([2., 1., 1.])\n",
      "Alignment score: 0.7638\n",
      "Perpendicular score: 0.6455\n",
      "Combined score: 0.8283\n",
      "\n",
      "3. Graph Neural Networks - Edge Directionality\n",
      "--------------------------------------------------\n",
      "Node 1 position: tensor([0., 0., 0.])\n",
      "Node 2 position: tensor([1., 1., 0.])\n",
      "Edge cross product: tensor([-0.4000,  0.4000,  0.7000])\n",
      "Edge strength: 0.9000\n"
     ]
    }
   ],
   "source": [
    "# DEEP LEARNING APPLICATIONS: \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEEP LEARNING APPLICATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Application 1: 3D CNN Feature Extraction\n",
    "print(\"1. 3D CNN Spatial Feature Relationships\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "def extract_3d_spatial_features(feature_map):\n",
    "    \"\"\"\n",
    "    Extract spatial relationships in 3D feature maps\n",
    "    Using cross product to find perpendicular feature directions\n",
    "    \"\"\"\n",
    "    # Simulate 3D feature gradients\n",
    "    grad_x = torch.tensor([1.0, 0.0, 0.0])\n",
    "    grad_y = torch.tensor([0.0, 1.0, 0.0])\n",
    "    grad_z = torch.tensor([0.0, 0.0, 1.0])\n",
    "    \n",
    "    # Cross products give perpendicular directions\n",
    "    perp_xy = torch.cross(grad_x, grad_y)\n",
    "    perp_xz = torch.cross(grad_x, grad_z)\n",
    "    perp_yz = torch.cross(grad_y, grad_z)\n",
    "    \n",
    "    return {\n",
    "        'perpendicular_xy': perp_xy,\n",
    "        'perpendicular_xz': perp_xz,\n",
    "        'perpendicular_yz': perp_yz\n",
    "    }\n",
    "\n",
    "spatial_features = extract_3d_spatial_features(None)\n",
    "print(\"3D spatial perpendicular directions:\")\n",
    "for name, direction in spatial_features.items():\n",
    "    print(f\"  {name}: {direction}\")\n",
    "\n",
    "# Application 2: Attention Mechanism Enhancement\n",
    "print(f\"\\n2. Attention Mechanism with Geometric Relationships\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "def geometric_attention_weights(query, key, value):\n",
    "    \"\"\"\n",
    "    Enhanced attention using both dot product and cross product\n",
    "    \"\"\"\n",
    "    # Standard dot product attention\n",
    "    dot_attention = torch.dot(query, key)\n",
    "    \n",
    "    # Cross product for perpendicular relationships\n",
    "    cross_prod = torch.cross(query, key)\n",
    "    cross_magnitude = torch.norm(cross_prod)\n",
    "    \n",
    "    # Combined attention score\n",
    "    # High dot product = aligned, low cross product = parallel\n",
    "    alignment_score = dot_attention / (torch.norm(query) * torch.norm(key))\n",
    "    perpendicular_score = cross_magnitude / (torch.norm(query) * torch.norm(key))\n",
    "    \n",
    "    return {\n",
    "        'alignment_score': alignment_score.item(),\n",
    "        'perpendicular_score': perpendicular_score.item(),\n",
    "        'combined_score': alignment_score.item() + 0.1 * perpendicular_score.item()\n",
    "    }\n",
    "\n",
    "# Example query, key, value vectors\n",
    "query = torch.tensor([1.0, 2.0, 3.0])\n",
    "key = torch.tensor([2.0, 1.0, 1.0])\n",
    "value = torch.tensor([3.0, 1.0, 2.0])\n",
    "\n",
    "attention_scores = geometric_attention_weights(query, key, value)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Key: {key}\")\n",
    "print(f\"Alignment score: {attention_scores['alignment_score']:.4f}\")\n",
    "print(f\"Perpendicular score: {attention_scores['perpendicular_score']:.4f}\")\n",
    "print(f\"Combined score: {attention_scores['combined_score']:.4f}\")\n",
    "\n",
    "# Application 3: Graph Neural Networks\n",
    "print(f\"\\n3. Graph Neural Networks - Edge Directionality\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def calculate_edge_features(node1_pos, node2_pos, node1_features, node2_features):\n",
    "    \"\"\"\n",
    "    Calculate edge features using cross product for directional information\n",
    "    \"\"\"\n",
    "    # Position difference\n",
    "    pos_diff = node2_pos - node1_pos\n",
    "    \n",
    "    # Feature difference\n",
    "    feature_diff = node2_features - node1_features\n",
    "    \n",
    "    # Cross product gives perpendicular direction\n",
    "    cross_feature = torch.cross(pos_diff, feature_diff)\n",
    "    \n",
    "    return {\n",
    "        'position_diff': pos_diff,\n",
    "        'feature_diff': feature_diff,\n",
    "        'cross_product': cross_feature,\n",
    "        'edge_strength': torch.norm(cross_feature)\n",
    "    }\n",
    "\n",
    "# Example nodes\n",
    "node1_position = torch.tensor([0.0, 0.0, 0.0])\n",
    "node2_position = torch.tensor([1.0, 1.0, 0.0])\n",
    "node1_features = torch.tensor([0.5, 0.3, 0.8])\n",
    "node2_features = torch.tensor([0.2, 0.7, 0.4])\n",
    "\n",
    "edge_features = calculate_edge_features(node1_position, node2_position, \n",
    "                                       node1_features, node2_features)\n",
    "print(f\"Node 1 position: {node1_position}\")\n",
    "print(f\"Node 2 position: {node2_position}\")\n",
    "print(f\"Edge cross product: {edge_features['cross_product']}\")\n",
    "print(f\"Edge strength: {edge_features['edge_strength']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f0c0c5",
   "metadata": {},
   "source": [
    "**LIMITATIONS AND CONSIDERATIONS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55b21020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LIMITATIONS AND CONSIDERATIONS\n",
      "======================================================================\n",
      "Cross Product Limitations:\n",
      "• Only defined in 3D space (and 7D)\n",
      "• Not commutative (anti-commutative)\n",
      "• Depends on coordinate system handedness\n",
      "• Zero for parallel vectors\n",
      "• Computationally more expensive than dot product\n",
      "\n",
      "When to Use Cross Product vs Dot Product:\n",
      "• Use cross product for:\n",
      "  - Finding perpendicular directions\n",
      "  - Calculating surface normals\n",
      "  - Rotation axis computation\n",
      "  - Area calculations\n",
      "  - Physics simulations\n",
      "• Use dot product for:\n",
      "  - Similarity measurements\n",
      "  - Projections\n",
      "  - Neural network computations\n",
      "  - Angle calculations\n",
      "  - General linear algebra operations\n",
      "\n",
      "======================================================================\n",
      "PRACTICAL IMPLEMENTATION TIPS\n",
      "======================================================================\n",
      "1. Always check for parallel vectors before using cross product\n",
      "2. Normalize vectors when direction matters more than magnitude\n",
      "3. Use cross product magnitude for area calculations\n",
      "4. Remember right-hand rule for direction\n",
      "5. Cross product is sensitive to vector order\n",
      "6. Consider numerical precision for near-parallel vectors\n",
      "\n",
      "Robust cross product test:\n",
      "Vectors: tensor([1., 0., 0.]), tensor([2., 0., 0.])\n",
      "Result: tensor([0., 0., 0.])\n",
      "Is parallel: True\n",
      "Message: Vectors are parallel or anti-parallel\n",
      "\n",
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Cross product is a powerful tool for 3D geometric computations,\n",
      "particularly useful in computer vision, robotics, and physics\n",
      "simulations. While less common than dot product in deep learning,\n",
      "it provides unique geometric insights for spatial relationships.\n"
     ]
    }
   ],
   "source": [
    "# LIMITATIONS AND CONSIDERATIONS: \n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LIMITATIONS AND CONSIDERATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"Cross Product Limitations:\")\n",
    "print(\"• Only defined in 3D space (and 7D)\")\n",
    "print(\"• Not commutative (anti-commutative)\")\n",
    "print(\"• Depends on coordinate system handedness\")\n",
    "print(\"• Zero for parallel vectors\")\n",
    "print(\"• Computationally more expensive than dot product\")\n",
    "\n",
    "print(\"\\nWhen to Use Cross Product vs Dot Product:\")\n",
    "print(\"• Use cross product for:\")\n",
    "print(\"  - Finding perpendicular directions\")\n",
    "print(\"  - Calculating surface normals\")\n",
    "print(\"  - Rotation axis computation\")\n",
    "print(\"  - Area calculations\")\n",
    "print(\"  - Physics simulations\")\n",
    "\n",
    "print(\"• Use dot product for:\")\n",
    "print(\"  - Similarity measurements\")\n",
    "print(\"  - Projections\")\n",
    "print(\"  - Neural network computations\")\n",
    "print(\"  - Angle calculations\")\n",
    "print(\"  - General linear algebra operations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PRACTICAL IMPLEMENTATION TIPS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"1. Always check for parallel vectors before using cross product\")\n",
    "print(\"2. Normalize vectors when direction matters more than magnitude\")\n",
    "print(\"3. Use cross product magnitude for area calculations\")\n",
    "print(\"4. Remember right-hand rule for direction\")\n",
    "print(\"5. Cross product is sensitive to vector order\")\n",
    "print(\"6. Consider numerical precision for near-parallel vectors\")\n",
    "\n",
    "# Example: Robust cross product with parallel vector check\n",
    "def robust_cross_product(a, b, epsilon=1e-6):\n",
    "    \"\"\"Cross product with parallel vector detection\"\"\"\n",
    "    cross = torch.cross(a, b)\n",
    "    magnitude = torch.norm(cross)\n",
    "    \n",
    "    if magnitude < epsilon:\n",
    "        return cross, True, \"Vectors are parallel or anti-parallel\"\n",
    "    else:\n",
    "        return cross, False, \"Cross product computed successfully\"\n",
    "\n",
    "# Test robust implementation\n",
    "test_a = torch.tensor([1.0, 0.0, 0.0])\n",
    "test_b = torch.tensor([2.0, 0.0, 0.0])  # Parallel\n",
    "\n",
    "result, is_parallel, message = robust_cross_product(test_a, test_b)\n",
    "print(f\"\\nRobust cross product test:\")\n",
    "print(f\"Vectors: {test_a}, {test_b}\")\n",
    "print(f\"Result: {result}\")\n",
    "print(f\"Is parallel: {is_parallel}\")\n",
    "print(f\"Message: {message}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(\"Cross product is a powerful tool for 3D geometric computations,\")\n",
    "print(\"particularly useful in computer vision, robotics, and physics\")\n",
    "print(\"simulations. While less common than dot product in deep learning,\")\n",
    "print(\"it provides unique geometric insights for spatial relationships.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95184fdf",
   "metadata": {},
   "source": [
    "### **Properties of Cross Product:**\n",
    "\n",
    "The cross product has several distinctive properties:\n",
    "\n",
    "1. **Anti-commutativity**: $a × b = -(b × a)$\n",
    "\n",
    "2. **Distributivity**: $a × (b + c) = a × b + a × c$\n",
    "\n",
    "3. **Scalar multiplication**: $(ka) × b = k(a × b) = a × (kb)$\n",
    "\n",
    "4. **Self cross product**: $a × a = 0$ (always zero)\n",
    "\n",
    "5. **Orthogonality**: $(a × b) ⊥ a$ and $(a × b) ⊥ b$\n",
    "\n",
    "6. **Parallel vectors**: If $a ∥ b,$ then $a × b = 0$\n",
    "\n",
    "7. **Magnitude formula**: $|a × b| = |a| |b| sin(θ)$\n",
    "\n",
    "8. **Right-hand rule**: Direction follows right-hand rule convention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6de33",
   "metadata": {},
   "source": [
    "### **Interpretation of Cross Product:**\n",
    "\n",
    "The cross product can be interpreted in several ways:\n",
    "\n",
    "**Geometric Interpretation:**\n",
    "   - The result vector is perpendicular to both input vectors\n",
    "   - Its magnitude equals the area of the parallelogram formed by the vectors\n",
    "   - Direction follows the right-hand rule\n",
    "\n",
    "**Physical Interpretation:**\n",
    "   - Represents rotation axis when transforming one vector to another\n",
    "   - Magnitude indicates the `\"amount of rotation\"` needed\n",
    "   - Used in torque, angular momentum, and magnetic field calculations\n",
    "\n",
    "**Algebraic Interpretation:**\n",
    "   - Provides a way to find orthogonal directions in 3D space\n",
    "   - Measures the `\"perpendicular component\"` of vector relationships\n",
    "   - Creates a basis for 3D coordinate transformations\n",
    "\n",
    "The cross product is particularly valuable when we need to find perpendicular directions, calculate areas, or work with rotational mechanics, making it essential for 3D computer graphics, robotics, and physics-based simulations in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9484e8d2",
   "metadata": {},
   "source": [
    "----\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cc422b",
   "metadata": {},
   "source": [
    "## **Vector Multiplication:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c544771",
   "metadata": {},
   "source": [
    "**Here are the different types of vector multiplication:**\n",
    "\n",
    "1. **Linear Algebra:**\n",
    "   - Dot product (scalar product)\n",
    "\n",
    "   - Cross product (vector product)\n",
    "\n",
    "   - Outer product (tensor product)\n",
    "\n",
    "   - Hadamard product (element-wise multiplication)\n",
    "\n",
    "2. **Deep Learning:**\n",
    "   - Element-wise multiplication (Hadamard product)\n",
    "\n",
    "   - Matrix multiplication (when treating vectors as matrices)\n",
    "\n",
    "   - Broadcast multiplication\n",
    "   \n",
    "   - Attention-weighted multiplication\n",
    "\n",
    "   - Gated multiplication (for gates in RNNs/LSTMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62253d96",
   "metadata": {},
   "source": [
    "## **Properties of Vector Product:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214159fd",
   "metadata": {},
   "source": [
    "1. **Dot Product Properties:**\n",
    "   - Commutative: $a · b = b · a$\n",
    "   - Distributive: $a · (b + c) = a · b + a · c$\n",
    "   - Associative with scalars: $(ka) · b = k(a · b)$\n",
    "   - Zero property: $a · 0 = 0$\n",
    "   - Self dot product: $a · a = ||a||²$\n",
    "   - Orthogonality: $a · b = 0$ if vectors are perpendicular\n",
    "\n",
    "2. **Cross Product Properties:**\n",
    "   - Anti-commutative: $a × b = -(b × a)$\n",
    "   - Distributive: $a × (b + c) = a × b + a × c$\n",
    "   - Zero property: $a × a = 0$\n",
    "   - Magnitude: $||a × b|| = ||a|| ||b|| sin θ$\n",
    "   - Orthogonal result: $a × b ⊥ a and a × b ⊥ b$\n",
    "\n",
    "3. **Hadamard Product Properties:**\n",
    "   - Commutative: $a ⊙ b = b ⊙ a$\n",
    "   - Associative: $(a ⊙ b) ⊙ c = a ⊙ (b ⊙ c)$\n",
    "   - Distributive: $a ⊙ (b + c) = a ⊙ b + a ⊙ c$\n",
    "   - Identity element: $a ⊙ 1 = a$\n",
    "   - Zero property: $a ⊙ 0 = 0$\n",
    "\n",
    "4. **Outer Product Properties:**\n",
    "    - Non-commutative: $a ⊗ b ≠ b ⊗ a$\n",
    "    - Bilinear: $(αa + βb) ⊗ c = α(a ⊗ c) + β(b ⊗ c)$\n",
    "    - Rank-1 matrices: $a ⊗ b$ produces rank-1 matrix\n",
    "    - Transpose: $(a ⊗ b)ᵀ = b ⊗ a$\n",
    "\n",
    "5. **Vector Database Specific Properties:**\n",
    "    - Cosine similarity: normalized dot product\n",
    "    - Euclidean distance: derived from dot product\n",
    "    - Triangle inequality: $||a + b|| ≤ ||a|| + ||b||$\n",
    "    - Cauchy-Schwarz: $|a · b| ≤ ||a|| ||b||$\n",
    "    - Linearity in high dimensions\n",
    "   - Approximate nearest neighbor compatibility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
