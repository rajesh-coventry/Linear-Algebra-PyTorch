{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850a7b5b",
   "metadata": {},
   "source": [
    "# **Vector Operations:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b11ee8",
   "metadata": {},
   "source": [
    "## **1. Vector Addition:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cdd63",
   "metadata": {},
   "source": [
    "Vector addition is the element-wise addition of two or more tensors of the same shape, where corresponding elements are added together.\n",
    "\n",
    "For two vectors **a** = $[a₁, a₂, ..., aₙ]$ and **b** = $[b₁, b₂, ..., bₙ]$:\n",
    "\n",
    "> $a + b = [a₁ + b₁, a₂ + b₂, ..., aₙ + bₙ]$\n",
    "\n",
    "**Properties:**\n",
    "   - Commutative: **$a + b = b + a$**\n",
    "   -  Associative: **$(a + b) + c = a + (b + c)$**\n",
    "   - Identity: **$a + 0 = a$**\n",
    "   - Inverse: **$a + (-a) = 0$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af0b6eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b = tensor([ 6,  8, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Method 1: Using + operator\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "b = torch.tensor([5, 6, 7, 8])\n",
    "result1 = a + b\n",
    "print(f\"a + b = {result1}\")  # [6, 8, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b476ed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.add(a, b) = tensor([ 6,  8, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Using torch.add()\n",
    "result2 = torch.add(a, b)\n",
    "print(f\"torch.add(a, b) = {result2}\")  # [6, 8, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dbd39e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a += b = tensor([ 6,  8, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "# Method 3: In-place addition with +=\n",
    "a_copy = a.clone()\n",
    "a_copy += b\n",
    "print(f\"a += b = {a_copy}\")  # [6, 8, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a96f8abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.add_(b) = tensor([ 6,  8, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "# Method 4: In-place addition with add_()\n",
    "a_copy2 = a.clone()\n",
    "a_copy2.add_(b)\n",
    "print(f\"a.add_(b) = {a_copy2}\")  # [6, 8, 10, 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5312e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + scalar = tensor([11, 12, 13, 14])\n"
     ]
    }
   ],
   "source": [
    "# Method 5: Adding scalar to vector\n",
    "scalar = 10\n",
    "result3 = a + scalar\n",
    "print(f\"a + scalar = {result3}\")  # [11, 12, 13, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b48f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b + c = tensor([ 7,  9, 11, 13])\n"
     ]
    }
   ],
   "source": [
    "# Method 6: Adding multiple vectors\n",
    "c = torch.tensor([1, 1, 1, 1])\n",
    "result4 = a + b + c\n",
    "print(f\"a + b + c = {result4}\")  # [7, 9, 11, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b3dc482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D + 1D broadcasting:\n",
      "tensor([[11, 22],\n",
      "        [13, 24]])\n"
     ]
    }
   ],
   "source": [
    "# Method 7: Broadcasting addition (different shapes)\n",
    "a_2d = torch.tensor([[1, 2], [3, 4]])\n",
    "b_1d = torch.tensor([10, 20])\n",
    "result5 = a_2d + b_1d  # Broadcasting\n",
    "print(f\"2D + 1D broadcasting:\\n{result5}\")\n",
    "# [[11, 22]\n",
    "#  [13, 24]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8898b1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + 5*b = tensor([26, 32, 38, 44])\n"
     ]
    }
   ],
   "source": [
    "# Method 8: Weighted addition\n",
    "alpha = 5\n",
    "beta = 0.3\n",
    "result6 = torch.add(a, b, alpha=alpha)  # a + alpha * b\n",
    "print(f\"a + 5*b = {result6}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd9c8b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float + int = tensor([2., 4., 6.])\n",
      "Result dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Method 9: Adding with different dtypes (automatic type promotion)\n",
    "a_float = torch.tensor([1.0, 2.0, 3.0])\n",
    "b_int = torch.tensor([1, 2, 3])\n",
    "result7 = a_float + b_int\n",
    "print(f\"float + int = {result7}\")  # [2.0, 4.0, 6.0]\n",
    "print(f\"Result dtype: {result7.dtype}\")  # torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6a6f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 10: GPU vector addition (if CUDA available)\n",
    "if torch.cuda.is_available():\n",
    "    a_gpu = torch.tensor([1, 2, 3, 4]).cuda()\n",
    "    b_gpu = torch.tensor([5, 6, 7, 8]).cuda()\n",
    "    result_gpu = a_gpu + b_gpu\n",
    "    print(f\"GPU addition: {result_gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a78f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of batch_a: torch.Size([32, 128])\n",
      "Shape of batch_b: torch.Size([32, 128])\n",
      "Batch addition shape: torch.Size([32, 128])\n"
     ]
    }
   ],
   "source": [
    "# Method 11: Batch vector addition\n",
    "\n",
    "batch_a = torch.randn(32, 128)  # 32 vectors of dimension 128\n",
    "batch_b = torch.randn(32, 128)\n",
    "batch_result = batch_a + batch_b\n",
    "print(f\"Shape of batch_a: {batch_a.shape}\")\n",
    "print(f\"Shape of batch_b: {batch_b.shape}\")\n",
    "print(f\"Batch addition shape: {batch_result.shape}\")  # torch.Size([32, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3efb2af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print a: tensor([1, 2, 3, 4])\n",
      "Print b: tensor([5, 6, 7, 8])\n",
      "Print output: tensor([ 6,  8, 10, 12])\n",
      "shape of output: torch.Size([4])\n",
      "Addition with output tensor: tensor([ 6,  8, 10, 12])\n"
     ]
    }
   ],
   "source": [
    "# Method 12: Element-wise addition with specific output tensor\n",
    "\n",
    "output = torch.empty_like(a)\n",
    "print(f\"Print a: {a}\")\n",
    "print(f\"Print b: {b}\")\n",
    "torch.add(a, b, out=output)\n",
    "print(f\"Print output: {output}\")\n",
    "print(f\"shape of output: {output.shape}\")\n",
    "print(f\"Addition with output tensor: {output}\")  # [6, 8, 10, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aefe8f",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "\n",
    "   1. **Broadcasting**: PyTorch automatically handles different tensor shapes when possible\n",
    "\n",
    "   2. **In-place operations**: Methods ending with `_` modify the original tensor\n",
    "\n",
    "   3. **Type promotion**: PyTorch automatically promotes to the most general dtype\n",
    "\n",
    "   4. **GPU support**: Operations work seamlessly on CUDA tensors\n",
    "\n",
    "   5. **Batch operations**: Addition works efficiently on batched data\n",
    "\n",
    "   6. **Memory efficiency**: Can specify output tensor to avoid extra memory allocation\n",
    "\n",
    "**Common Use Cases in Deep Learning:**\n",
    "   - Adding bias terms to linear layers\n",
    "\n",
    "   - Residual connections in neural networks\n",
    "\n",
    "   - Combining feature representations\n",
    "\n",
    "   - Gradient accumulation during backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60106ab",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d92733",
   "metadata": {},
   "source": [
    "## **2. Broadcasting:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab4159",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3d2a5a5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
